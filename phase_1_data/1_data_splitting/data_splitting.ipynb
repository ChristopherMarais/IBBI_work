{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7012b09c-6931-429e-be3a-f9e6b1aaca82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, KFold\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19db399d-7a47-4594-9dcb-086c585c884a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Initial df_species shape: (235, 3)\n",
      "Initial df_images shape: (54421, 10)\n",
      "\n",
      "Filtering species dataframe (for classification dataset)...\n",
      "Number of species after filtering: 63\n",
      "First 10 selected species names for classification: ['Ambrosiodmus_minor' 'Ambrosiophilus_atratus' 'Anisandrus_dispar'\n",
      " 'Anisandrus_sayi' 'Cnestus_mutilatus' 'Coccotrypes_carpophagus'\n",
      " 'Coccotrypes_dactyliperda' 'Coptoborus_ricini' 'Cryptocarenus_heveae'\n",
      " 'Ctonoxylon_hagedorn'] ...\n",
      "\n",
      "Filtering images dataframe (for classification dataset)...\n",
      "Constructing 'full_species_name' in df_images_for_classification...\n",
      "Number of images for classification dataset after filtering: 13538\n",
      "\n",
      "Class distribution in filtered classification image data (top 10):\n",
      "full_species_name\n",
      "Ips_typographus              2093\n",
      "Dendroctonus_valens          1759\n",
      "Ips_sexdentatus              1516\n",
      "Ips_acuminatus                964\n",
      "Hylesinus_varius              519\n",
      "Xylosandrus_crassiusculus     399\n",
      "Dendroctonus_terebrans        309\n",
      "Platypus_cylindrus            286\n",
      "Monarthrum_fasciatum          280\n",
      "Xyleborinus_saxesenii         270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Creating test set (from classification data, 15%)...\n",
      "Test set size: 2031 images\n",
      "Data for classification folds: 11507 images\n",
      "Test set class distribution (normalized, top 5):\n",
      "full_species_name\n",
      "Ips_typographus        0.154604\n",
      "Dendroctonus_valens    0.129985\n",
      "Ips_sexdentatus        0.111768\n",
      "Ips_acuminatus         0.071393\n",
      "Hylesinus_varius       0.038405\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Copying test set files...\n",
      "Copied 2031 images to ./test_set_output/.\n",
      "\n",
      "Creating 5 classification folds...\n",
      "\n",
      "--- Processing Classification Fold 1 ---\n",
      "Size: 2302 images. Path: ./classification_folds_output/fold1\n",
      "Copied 2302 images to ./classification_folds_output/fold1.\n",
      "\n",
      "--- Processing Classification Fold 2 ---\n",
      "Size: 2302 images. Path: ./classification_folds_output/fold2\n",
      "Copied 2302 images to ./classification_folds_output/fold2.\n",
      "\n",
      "--- Processing Classification Fold 3 ---\n",
      "Size: 2301 images. Path: ./classification_folds_output/fold3\n",
      "Copied 2301 images to ./classification_folds_output/fold3.\n",
      "\n",
      "--- Processing Classification Fold 4 ---\n",
      "Size: 2301 images. Path: ./classification_folds_output/fold4\n",
      "Copied 2301 images to ./classification_folds_output/fold4.\n",
      "\n",
      "--- Processing Classification Fold 5 ---\n",
      "Size: 2301 images. Path: ./classification_folds_output/fold5\n",
      "Copied 2301 images to ./classification_folds_output/fold5.\n",
      "\n",
      "Creating 5 detection folds...\n",
      "Number of images initially with num_shapes >= 1: 51230\n",
      "Number of images for detection folds (after excluding test set): 49199\n",
      "\n",
      "Splitting detection data into 5 folds (non-stratified, shuffled).\n",
      "\n",
      "--- Processing Detection Fold 1 ---\n",
      "Size: 9840 images. Path: ./detection_folds_output/detection_fold1\n",
      "Copied 9840 images to ./detection_folds_output/detection_fold1.\n",
      "\n",
      "--- Processing Detection Fold 2 ---\n",
      "Size: 9840 images. Path: ./detection_folds_output/detection_fold2\n",
      "Copied 9840 images to ./detection_folds_output/detection_fold2.\n",
      "\n",
      "--- Processing Detection Fold 3 ---\n",
      "Size: 9840 images. Path: ./detection_folds_output/detection_fold3\n",
      "Copied 9840 images to ./detection_folds_output/detection_fold3.\n",
      "\n",
      "--- Processing Detection Fold 4 ---\n",
      "Size: 9840 images. Path: ./detection_folds_output/detection_fold4\n",
      "Copied 9840 images to ./detection_folds_output/detection_fold4.\n",
      "\n",
      "--- Processing Detection Fold 5 ---\n",
      "Size: 9839 images. Path: ./detection_folds_output/detection_fold5\n",
      "Copied 9839 images to ./detection_folds_output/detection_fold5.\n",
      "\n",
      "--- Script Finished ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, KFold # KFold is already imported\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "# !!! IMPORTANT: Update these paths to match your environment !!!\n",
    "SPECIES_CSV_PATH = \"../20250515/species_summary_stats.csv\"\n",
    "IMAGES_CSV_PATH = \"../20250515/image_metadata.csv\"\n",
    "SOURCE_FILES_BASE_PATH = \"../20250515/data/\"  # Folder containing the actual image and JSON files\n",
    "\n",
    "# --- New Output Locations ---\n",
    "DESTINATION_TEST_SET_PATH = \"./test_set_output/\" # Specific location for the test set\n",
    "DESTINATION_CLASSIFICATION_FOLDS_BASE_PATH = \"./classification_folds_output/\" # Base for fold1, fold2 (species specific)\n",
    "DESTINATION_DETECTION_FOLDS_BASE_PATH = \"./detection_folds_output/\" # Base for detection_fold1, detection_fold2 (num_shapes >=1, no species limit)\n",
    "\n",
    "\n",
    "# --- Helper Function to Copy Files ---\n",
    "def copy_files_to_destination(df_subset, image_column_name, source_base_path, destination_folder_path):\n",
    "    \"\"\"\n",
    "    Copies image and its corresponding JSON file from source to destination.\n",
    "    Assumes JSON file has the same name as the image file but with a .json extension.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder_path):\n",
    "        os.makedirs(destination_folder_path, exist_ok=True)\n",
    "\n",
    "    copied_count = 0\n",
    "    skipped_image_not_found = 0\n",
    "    skipped_json_not_found = 0\n",
    "\n",
    "    for index, row in df_subset.iterrows():\n",
    "        image_filename = row[image_column_name]\n",
    "        if not isinstance(image_filename, str):\n",
    "            print(f\"Warning: Image filename is not a string, skipping row: {row}\")\n",
    "            skipped_image_not_found +=1\n",
    "            continue\n",
    "\n",
    "        base_name, img_ext = os.path.splitext(image_filename)\n",
    "        json_filename = base_name + \".json\"\n",
    "\n",
    "        source_image_full_path = os.path.join(source_base_path, image_filename)\n",
    "        source_json_full_path = os.path.join(source_base_path, json_filename)\n",
    "\n",
    "        dest_image_full_path = os.path.join(destination_folder_path, image_filename)\n",
    "        dest_json_full_path = os.path.join(destination_folder_path, json_filename)\n",
    "\n",
    "        if os.path.exists(source_image_full_path):\n",
    "            shutil.copy2(source_image_full_path, dest_image_full_path)\n",
    "            copied_count += 1\n",
    "\n",
    "            if os.path.exists(source_json_full_path):\n",
    "                shutil.copy2(source_json_full_path, dest_json_full_path)\n",
    "            else:\n",
    "                print(f\"Warning: JSON file not found for {image_filename} (image was copied): {source_json_full_path}\")\n",
    "                skipped_json_not_found +=1\n",
    "        else:\n",
    "            print(f\"Warning: Image file not found, skipping: {source_image_full_path}\")\n",
    "            skipped_image_not_found += 1\n",
    "            continue # If image not found, don't try to copy JSON\n",
    "\n",
    "\n",
    "    print(f\"Copied {copied_count} images to {destination_folder_path}.\")\n",
    "    if skipped_image_not_found > 0:\n",
    "        print(f\"Skipped {skipped_image_not_found} images (source file not found or invalid filename).\")\n",
    "    if skipped_json_not_found > 0:\n",
    "        print(f\"For {skipped_json_not_found} copied images, their corresponding JSON files were not found (but images were copied).\")\n",
    "\n",
    "\n",
    "# --- Main Script Logic ---\n",
    "def main():\n",
    "    # Create all base destination directories if they don't exist\n",
    "    os.makedirs(DESTINATION_TEST_SET_PATH, exist_ok=True)\n",
    "    os.makedirs(DESTINATION_CLASSIFICATION_FOLDS_BASE_PATH, exist_ok=True)\n",
    "    os.makedirs(DESTINATION_DETECTION_FOLDS_BASE_PATH, exist_ok=True)\n",
    "\n",
    "    # --- 1. Load Data ---\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        df_species = pd.read_csv(SPECIES_CSV_PATH)\n",
    "        df_images = pd.read_csv(IMAGES_CSV_PATH)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: CSV file not found. {e}\")\n",
    "        print(f\"Please ensure '{SPECIES_CSV_PATH}' and '{IMAGES_CSV_PATH}' are correct.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Initial df_species shape: {df_species.shape}\")\n",
    "    print(f\"Initial df_images shape: {df_images.shape}\\n\")\n",
    "\n",
    "    # --- 2. Filter df_species (for classification dataset) ---\n",
    "    print(\"Filtering species dataframe (for classification dataset)...\")\n",
    "    df_species['full_species_name'] = df_species['full_species_name'].astype(str)\n",
    "    df_species_filtered = df_species[\n",
    "        (df_species['total_shapes'] >= 50) &\n",
    "        (df_species['num_images'] > 50) &\n",
    "        (~df_species['full_species_name'].str.contains(\"unknown\", case=False, na=False)) &\n",
    "        (df_species['full_species_name'].str.lower() != \"nan\")\n",
    "    ]\n",
    "    valid_species_names = df_species_filtered['full_species_name'].unique()\n",
    "    print(f\"Number of species after filtering: {len(valid_species_names)}\")\n",
    "    if not len(valid_species_names):\n",
    "        print(\"No species meet the criteria from df_species for classification dataset. Classification folds might be empty or skipped.\")\n",
    "    else:\n",
    "        print(f\"First 10 selected species names for classification: {valid_species_names[:10]} ...\\n\")\n",
    "\n",
    "    # --- 3. Filter df_images (for classification dataset) ---\n",
    "    print(\"Filtering images dataframe (for classification dataset)...\")\n",
    "    df_images_for_classification = df_images.copy()\n",
    "\n",
    "    if 'full_species_name' not in df_images_for_classification.columns:\n",
    "        if 'genus' in df_images_for_classification.columns and 'species' in df_images_for_classification.columns:\n",
    "            print(\"Constructing 'full_species_name' in df_images_for_classification...\")\n",
    "            df_genus_str = df_images_for_classification['genus'].astype(str).fillna('')\n",
    "            df_species_str = df_images_for_classification['species'].astype(str).fillna('')\n",
    "            df_images_for_classification['full_species_name'] = df_genus_str + \"_\" + df_species_str\n",
    "            df_images_for_classification.loc[df_images_for_classification['full_species_name'] == '_', 'full_species_name'] = 'unknown_both_empty'\n",
    "        else:\n",
    "            print(\"Error: 'full_species_name' not in df_images_for_classification, and 'genus'/'species' cols missing.\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"'full_species_name' column already exists in df_images_for_classification. Assuming correct format.\")\n",
    "\n",
    "    df_images_for_classification['full_species_name'] = df_images_for_classification['full_species_name'].astype(str)\n",
    "    df_images_classification_filtered = df_images_for_classification[\n",
    "        df_images_for_classification['full_species_name'].isin(valid_species_names) &\n",
    "        (df_images_for_classification['num_shapes'] >= 1)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"Number of images for classification dataset after filtering: {df_images_classification_filtered.shape[0]}\")\n",
    "    \n",
    "    df_test = pd.DataFrame() \n",
    "    df_train_val_classification = pd.DataFrame() \n",
    "\n",
    "    if df_images_classification_filtered.empty:\n",
    "        print(\"No images meet criteria for classification dataset. Test set and classification folds will be empty/skipped.\")\n",
    "    else:\n",
    "        stratify_column_classification = 'full_species_name'\n",
    "        df_images_classification_filtered[stratify_column_classification] = df_images_classification_filtered[stratify_column_classification].fillna('unknown_species_final')\n",
    "        class_counts_classification = df_images_classification_filtered[stratify_column_classification].value_counts()\n",
    "        print(\"\\nClass distribution in filtered classification image data (top 10):\")\n",
    "        print(class_counts_classification.head(10))\n",
    "\n",
    "        if class_counts_classification.empty:\n",
    "            print(\"No class data for classification stratification. Test set/classification folds might be problematic.\")\n",
    "        else:\n",
    "            # --- 4. Create Test Set (from classification filtered data) ---\n",
    "            print(\"\\nCreating test set (from classification data, 15%)...\")\n",
    "            if df_images_classification_filtered.shape[0] < 2:\n",
    "                print(\"Not enough data for test split. Test set will be empty.\")\n",
    "                df_train_val_classification = df_images_classification_filtered.copy()\n",
    "            else:\n",
    "                if (class_counts_classification < 2).any():\n",
    "                    print(\"\\nWarning: Some classes (classification) have only 1 sample. Stratified test split problematic.\")\n",
    "                \n",
    "                sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "                X_indices_cls = df_images_classification_filtered.index\n",
    "                y_labels_cls = df_images_classification_filtered[stratify_column_classification]\n",
    "                try:\n",
    "                    train_val_indices_cls, test_indices_cls = next(sss.split(X_indices_cls, y_labels_cls))\n",
    "                    df_test = df_images_classification_filtered.loc[X_indices_cls[test_indices_cls]]\n",
    "                    df_train_val_classification = df_images_classification_filtered.loc[X_indices_cls[train_val_indices_cls]]\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error during test set splitting: {e}. Test set may be empty. Using all for train/val.\")\n",
    "                    df_train_val_classification = df_images_classification_filtered.copy()\n",
    "\n",
    "            print(f\"Test set size: {df_test.shape[0]} images\")\n",
    "            print(f\"Data for classification folds: {df_train_val_classification.shape[0]} images\")\n",
    "            if not df_test.empty:\n",
    "                print(\"Test set class distribution (normalized, top 5):\")\n",
    "                print(df_test[stratify_column_classification].value_counts(normalize=True).head())\n",
    "\n",
    "            # --- 5. Copy Test Set Files ---\n",
    "            print(\"\\nCopying test set files...\")\n",
    "            if not df_test.empty:\n",
    "                copy_files_to_destination(df_test, 'image_name', SOURCE_FILES_BASE_PATH, DESTINATION_TEST_SET_PATH)\n",
    "            else:\n",
    "                print(\"Test set is empty, no files to copy.\")\n",
    "\n",
    "            # --- 6. Create Classification Folds ---\n",
    "            print(\"\\nCreating 5 classification folds...\")\n",
    "            N_CLASSIFICATION_FOLDS = 5\n",
    "            if df_train_val_classification.empty or df_train_val_classification.shape[0] < N_CLASSIFICATION_FOLDS:\n",
    "                print(f\"Not enough data for {N_CLASSIFICATION_FOLDS} classification folds. Skipping.\")\n",
    "            else:\n",
    "                cls_fold_class_counts = df_train_val_classification[stratify_column_classification].value_counts()\n",
    "                if (cls_fold_class_counts < N_CLASSIFICATION_FOLDS).any():\n",
    "                    print(f\"\\nWarning: Some classes for classification folds have fewer than {N_CLASSIFICATION_FOLDS} samples. Stratification problematic.\")\n",
    "                \n",
    "                skf_classification = StratifiedKFold(n_splits=N_CLASSIFICATION_FOLDS, shuffle=True, random_state=42)\n",
    "                X_cv_cls_indices = df_train_val_classification.index\n",
    "                y_cv_cls_labels = df_train_val_classification[stratify_column_classification]\n",
    "                fold_num_cls = 1\n",
    "                try:\n",
    "                    for _, val_fold_indices_pos_cls in skf_classification.split(X_cv_cls_indices, y_cv_cls_labels):\n",
    "                        current_fold_df_indices_cls = X_cv_cls_indices[val_fold_indices_pos_cls]\n",
    "                        df_current_cls_fold = df_train_val_classification.loc[current_fold_df_indices_cls]\n",
    "                        cls_fold_dest_path = os.path.join(DESTINATION_CLASSIFICATION_FOLDS_BASE_PATH, f\"fold{fold_num_cls}\")\n",
    "                        \n",
    "                        print(f\"\\n--- Processing Classification Fold {fold_num_cls} ---\")\n",
    "                        print(f\"Size: {df_current_cls_fold.shape[0]} images. Path: {cls_fold_dest_path}\")\n",
    "                        if not df_current_cls_fold.empty:\n",
    "                            copy_files_to_destination(df_current_cls_fold, 'image_name', SOURCE_FILES_BASE_PATH, cls_fold_dest_path)\n",
    "                        fold_num_cls += 1\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error during Classification K-Fold splitting: {e}\")\n",
    "\n",
    "    # --- 7. Create Detection Folds (num_shapes >= 1, excluding test set images) ---\n",
    "    print(\"\\nCreating 5 detection folds...\")\n",
    "    df_detection_source = df_images[df_images['num_shapes'] >= 1].copy()\n",
    "    print(f\"Number of images initially with num_shapes >= 1: {df_detection_source.shape[0]}\")\n",
    "\n",
    "    if not df_test.empty: \n",
    "        test_set_image_names = df_test['image_name'].unique()\n",
    "        df_detection_candidates = df_detection_source[~df_detection_source['image_name'].isin(test_set_image_names)].copy()\n",
    "        print(f\"Number of images for detection folds (after excluding test set): {df_detection_candidates.shape[0]}\")\n",
    "    else:\n",
    "        print(\"Test set (df_test) was empty. Using all images with num_shapes >= 1 for detection folds.\")\n",
    "        df_detection_candidates = df_detection_source.copy()\n",
    "\n",
    "    if df_detection_candidates.empty:\n",
    "        print(\"No images available for detection folds. Skipping this step.\")\n",
    "    else:\n",
    "        N_DETECTION_FOLDS = 5\n",
    "        if df_detection_candidates.shape[0] < N_DETECTION_FOLDS:\n",
    "            print(f\"Not enough data ({df_detection_candidates.shape[0]}) for {N_DETECTION_FOLDS} detection folds. Skipping.\")\n",
    "        else:\n",
    "            # User specified class distribution does not matter for detection data.\n",
    "            # Using KFold for non-stratified splitting. Shuffle for randomness.\n",
    "            print(f\"\\nSplitting detection data into {N_DETECTION_FOLDS} folds (non-stratified, shuffled).\")\n",
    "            kf_detection = KFold(n_splits=N_DETECTION_FOLDS, shuffle=True, random_state=123) # Using KFold\n",
    "            \n",
    "            X_detection_indices = df_detection_candidates.index # We'll split based on these indices\n",
    "\n",
    "            fold_num_det = 1\n",
    "            # KFold.split(X) yields (train_indices, test_indices) relative to X.\n",
    "            # We are interested in the 'test_indices' part (val_fold_indices_pos_det) for each fold's content.\n",
    "            for _, val_fold_indices_pos_det in kf_detection.split(X_detection_indices): # No y_labels needed for KFold\n",
    "                current_fold_df_indices_det = X_detection_indices[val_fold_indices_pos_det]\n",
    "                df_current_detection_fold = df_detection_candidates.loc[current_fold_df_indices_det]\n",
    "                \n",
    "                det_fold_dest_path = os.path.join(DESTINATION_DETECTION_FOLDS_BASE_PATH, f\"detection_fold{fold_num_det}\")\n",
    "\n",
    "                print(f\"\\n--- Processing Detection Fold {fold_num_det} ---\")\n",
    "                print(f\"Size: {df_current_detection_fold.shape[0]} images. Path: {det_fold_dest_path}\")\n",
    "\n",
    "                if not df_current_detection_fold.empty:\n",
    "                    copy_files_to_destination(df_current_detection_fold, 'image_name', SOURCE_FILES_BASE_PATH, det_fold_dest_path)\n",
    "                fold_num_det += 1\n",
    "            # No specific ValueError for stratification issues is expected here with KFold\n",
    "\n",
    "    print(\"\\n--- Script Finished ---\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacce94-aba8-403b-87f1-d8a5512268c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
