{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e54cef-8479-4a2d-b29f-de7d8281ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the ENTIRE Python script from the previous response here.\n",
    "# This includes all imports, all function definitions:\n",
    "# convert_yolo_format, get_fixed_class_map, _process_single_image_json_pair,\n",
    "# process_single_fold_for_yolo_parallel, and create_kfold_yolo_datasets.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import yaml # For data.yaml\n",
    "from PIL import Image # To verify/get image dimensions if needed\n",
    "import concurrent.futures\n",
    "import time # For timing\n",
    "\n",
    "# --- Utility Functions (largely unchanged but crucial) ---\n",
    "def convert_yolo_format(image_width, image_height, points, class_id):\n",
    "    # ... (full function code as provided before) ...\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "\n",
    "    x_min_abs = min(x_coords)\n",
    "    y_min_abs = min(y_coords)\n",
    "    x_max_abs = max(x_coords)\n",
    "    y_max_abs = max(y_coords)\n",
    "\n",
    "    x_min_abs = max(0, x_min_abs)\n",
    "    y_min_abs = max(0, y_min_abs)\n",
    "    x_max_abs = min(image_width - 1, x_max_abs)\n",
    "    y_max_abs = min(image_height - 1, y_max_abs)\n",
    "\n",
    "    if x_min_abs >= x_max_abs or y_min_abs >= y_max_abs:\n",
    "        return None\n",
    "\n",
    "    box_width_abs = x_max_abs - x_min_abs\n",
    "    box_height_abs = y_max_abs - y_min_abs\n",
    "\n",
    "    x_center_abs = x_min_abs + box_width_abs / 2.0\n",
    "    y_center_abs = y_min_abs + box_height_abs / 2.0\n",
    "\n",
    "    x_center_norm = x_center_abs / image_width\n",
    "    y_center_norm = y_center_abs / image_height\n",
    "    width_norm = box_width_abs / image_width\n",
    "    height_norm = box_height_abs / image_height\n",
    "\n",
    "    return f\"{class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
    "\n",
    "\n",
    "# --- Modified Class \"Discovery\" ---\n",
    "def get_fixed_class_map():\n",
    "    # ... (full function code as provided before) ...\n",
    "    print(\"Setting up fixed class: 'bark_beetle'\")\n",
    "    master_class_to_id_map = OrderedDict([(\"bark_beetle\", 0)])\n",
    "    print(f\"Using 1 class:\")\n",
    "    for name, idx in master_class_to_id_map.items():\n",
    "        print(f\"  '{name}': {idx}\")\n",
    "    return master_class_to_id_map\n",
    "\n",
    "\n",
    "# --- Parallelized File Processing for a Single Fold ---\n",
    "def _process_single_image_json_pair(args_tuple):\n",
    "    # ... (full function code as provided before) ...\n",
    "    img_filename_no_ext, source_fold_path, master_class_to_id_map, \\\n",
    "    output_images_dir, output_labels_dir = args_tuple\n",
    "\n",
    "    bark_beetle_class_id = master_class_to_id_map[\"bark_beetle\"]\n",
    "    png_file = f\"{img_filename_no_ext}.png\"\n",
    "    json_file = f\"{img_filename_no_ext}.json\"\n",
    "    source_png_path = os.path.join(source_fold_path, png_file)\n",
    "    source_json_path = os.path.join(source_fold_path, json_file)\n",
    "\n",
    "    if not (os.path.exists(source_png_path) and os.path.exists(source_json_path)):\n",
    "        return False\n",
    "    dest_png_path = os.path.join(output_images_dir, png_file)\n",
    "    try:\n",
    "        shutil.copy2(source_png_path, dest_png_path)\n",
    "        with open(source_json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "        return False\n",
    "    image_height = data.get(\"imageHeight\")\n",
    "    image_width = data.get(\"imageWidth\")\n",
    "    if image_height is None or image_width is None:\n",
    "        try:\n",
    "            with Image.open(source_png_path) as img:\n",
    "                image_width_pil, image_height_pil = img.size\n",
    "            if image_height is None: image_height = image_height_pil\n",
    "            if image_width is None: image_width = image_width_pil\n",
    "        except Exception:\n",
    "            if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "            return False\n",
    "    if not image_height or not image_width:\n",
    "        if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "        return False\n",
    "    yolo_annotations = []\n",
    "    for shape in data.get(\"shapes\", []):\n",
    "        points = shape.get(\"points\")\n",
    "        shape_type = shape.get(\"shape_type\")\n",
    "        if not points or shape_type != \"rectangle\" or len(points) != 2:\n",
    "            continue\n",
    "        yolo_str = convert_yolo_format(image_width, image_height, points, bark_beetle_class_id)\n",
    "        if yolo_str:\n",
    "            yolo_annotations.append(yolo_str)\n",
    "    if yolo_annotations:\n",
    "        dest_label_path = os.path.join(output_labels_dir, f\"{img_filename_no_ext}.txt\")\n",
    "        with open(dest_label_path, 'w') as f_label:\n",
    "            f_label.write(\"\\n\".join(yolo_annotations) + \"\\n\")\n",
    "        return True\n",
    "    elif os.path.exists(dest_png_path):\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_single_fold_for_yolo_parallel(source_fold_path, image_basenames_in_fold,\n",
    "                                          master_class_to_id_map,\n",
    "                                          output_images_dir, output_labels_dir, max_workers=None):\n",
    "    # ... (full function code as provided before) ...\n",
    "    processed_count = 0\n",
    "    tasks = []\n",
    "    for img_basename in image_basenames_in_fold:\n",
    "        tasks.append((img_basename, source_fold_path, master_class_to_id_map,\n",
    "                      output_images_dir, output_labels_dir))\n",
    "    if not tasks:\n",
    "        return 0\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(_process_single_image_json_pair, task_args): task_args for task_args in tasks}\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            try:\n",
    "                if future.result():\n",
    "                    processed_count += 1\n",
    "            except Exception as exc:\n",
    "                pass\n",
    "    return processed_count\n",
    "\n",
    "\n",
    "# --- Main Orchestrator Function for Jupyter Notebook ---\n",
    "def create_kfold_yolo_datasets(source_dir, base_dest_dir, source_fold_names_str, max_workers=None):\n",
    "    # ... (full function code as provided before) ...\n",
    "    overall_start_time = time.time()\n",
    "    all_original_fold_names = [name.strip() for name in source_fold_names_str.split(',') if name.strip()]\n",
    "    if not all_original_fold_names or len(all_original_fold_names) < 2:\n",
    "        print(\"Error: Please provide at least two source fold names for cross-validation.\")\n",
    "        return\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print(f\"Error: Source directory '{source_dir}' not found.\")\n",
    "        return\n",
    "    os.makedirs(base_dest_dir, exist_ok=True)\n",
    "    master_class_to_id_map = get_fixed_class_map()\n",
    "    num_cv_folds = len(all_original_fold_names)\n",
    "    print(f\"\\nPreparing data for {num_cv_folds}-Fold Cross-Validation (all objects as 'bark_beetle')...\")\n",
    "    for i in range(num_cv_folds):\n",
    "        cv_iteration_start_time = time.time()\n",
    "        current_val_fold_name = all_original_fold_names[i]\n",
    "        current_train_fold_names = [f_name for idx, f_name in enumerate(all_original_fold_names) if idx != i]\n",
    "        cv_iteration_dir_name = f\"cv_iteration_{i+1}\"\n",
    "        current_cv_split_output_root = os.path.join(base_dest_dir, cv_iteration_dir_name)\n",
    "        print(f\"\\n--- Processing CV Iteration {i+1}/{num_cv_folds} ---\")\n",
    "        print(f\"  Validation Fold: {current_val_fold_name}\")\n",
    "        print(f\"  Training Folds: {', '.join(current_train_fold_names)}\")\n",
    "        print(f\"  Output to: {current_cv_split_output_root}\")\n",
    "        train_images_dir = os.path.join(current_cv_split_output_root, \"images\", \"train\")\n",
    "        train_labels_dir = os.path.join(current_cv_split_output_root, \"labels\", \"train\")\n",
    "        val_images_dir = os.path.join(current_cv_split_output_root, \"images\", \"val\")\n",
    "        val_labels_dir = os.path.join(current_cv_split_output_root, \"labels\", \"val\")\n",
    "        os.makedirs(train_images_dir, exist_ok=True)\n",
    "        os.makedirs(train_labels_dir, exist_ok=True)\n",
    "        os.makedirs(val_images_dir, exist_ok=True)\n",
    "        os.makedirs(val_labels_dir, exist_ok=True)\n",
    "        print(f\"  Processing training data for CV Iteration {i+1}...\")\n",
    "        total_train_images_for_cv_iter = 0\n",
    "        for train_fold_name in current_train_fold_names:\n",
    "            fold_proc_start_time = time.time()\n",
    "            source_fold_path = os.path.join(source_dir, train_fold_name)\n",
    "            if not os.path.isdir(source_fold_path):\n",
    "                print(f\"  Warning: Training source fold '{source_fold_path}' not found. Skipping.\")\n",
    "                continue\n",
    "            image_basenames = {os.path.splitext(f)[0] for f in os.listdir(source_fold_path) if f.lower().endswith(\".png\")}\n",
    "            if not image_basenames:\n",
    "                print(f\"  No PNG images found in training source fold '{source_fold_path}'.\")\n",
    "                continue\n",
    "            count = process_single_fold_for_yolo_parallel(\n",
    "                source_fold_path, list(image_basenames), master_class_to_id_map,\n",
    "                train_images_dir, train_labels_dir, max_workers\n",
    "            )\n",
    "            total_train_images_for_cv_iter += count\n",
    "            fold_proc_time = time.time() - fold_proc_start_time\n",
    "            print(f\"    Processed {count} image files (labels generated if objects found) from source train fold '{train_fold_name}' in {fold_proc_time:.2f}s.\")\n",
    "        print(f\"  Total training images with labels for CV Iteration {i+1}: {total_train_images_for_cv_iter}\")\n",
    "        print(f\"  Processing validation data for CV Iteration {i+1}...\")\n",
    "        total_val_images_for_cv_iter = 0\n",
    "        source_val_fold_path = os.path.join(source_dir, current_val_fold_name)\n",
    "        if not os.path.isdir(source_val_fold_path):\n",
    "            print(f\"  Warning: Validation source fold '{source_val_fold_path}' not found. Skipping val set for this iter.\")\n",
    "        else:\n",
    "            fold_proc_start_time = time.time()\n",
    "            image_basenames_val = {os.path.splitext(f)[0] for f in os.listdir(source_val_fold_path) if f.lower().endswith(\".png\")}\n",
    "            if not image_basenames_val:\n",
    "                print(f\"  No PNG images found in validation source fold '{source_val_fold_path}'.\")\n",
    "            else:\n",
    "                count_val = process_single_fold_for_yolo_parallel(\n",
    "                    source_val_fold_path, list(image_basenames_val), master_class_to_id_map,\n",
    "                    val_images_dir, val_labels_dir, max_workers\n",
    "                )\n",
    "                total_val_images_for_cv_iter = count_val\n",
    "                fold_proc_time = time.time() - fold_proc_start_time\n",
    "                print(f\"    Processed {count_val} image files (labels generated if objects found) from source validation fold '{current_val_fold_name}' in {fold_proc_time:.2f}s.\")\n",
    "        print(f\"  Total validation images with labels for CV Iteration {i+1}: {total_val_images_for_cv_iter}\")\n",
    "        data_yaml_content = {\n",
    "            'path': os.path.abspath(current_cv_split_output_root),\n",
    "            'train': os.path.join('images', 'train'),\n",
    "            'val': os.path.join('images', 'val'),\n",
    "            'nc': len(master_class_to_id_map),\n",
    "            'names': list(master_class_to_id_map.keys())\n",
    "        }\n",
    "        data_yaml_path = os.path.join(current_cv_split_output_root, \"data.yaml\")\n",
    "        try:\n",
    "            with open(data_yaml_path, 'w') as f:\n",
    "                yaml.dump(data_yaml_content, f, sort_keys=False, default_flow_style=False)\n",
    "            cv_iteration_time = time.time() - cv_iteration_start_time\n",
    "            print(f\"  Successfully created 'data.yaml' for CV Iteration {i+1}. Iteration took {cv_iteration_time:.2f}s.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error writing data.yaml for CV Iteration {i+1}: {e}\")\n",
    "    total_script_time = time.time() - overall_start_time\n",
    "    print(f\"\\n{num_cv_folds}-Fold Cross-Validation dataset preparation complete in {total_script_time:.2f} seconds!\")\n",
    "    print(f\"All CV iteration datasets are ready under: {base_dest_dir}\")\n",
    "    print(\"All objects have been mapped to the class 'bark_beetle'.\")\n",
    "\n",
    "# Note: The actual call to create_kfold_yolo_datasets will be in the next cell.\n",
    "# Ensure this cell is run first to define all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91af1ca-ce0f-413b-ae41-ab7c384963ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation with 'bark_beetle' as the single class:\n",
      "  Source Directory: /blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/detection_folds_output\n",
      "  Base Destination Directory: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/ultralytics\n",
      "  Source Fold Names: ['detection_fold1', 'detection_fold2', 'detection_fold3', 'detection_fold4', 'detection_fold5']\n",
      "  Max Workers for Parallelization: 6\n",
      "------------------------------\n",
      "Setting up fixed class: 'bark_beetle'\n",
      "Using 1 class:\n",
      "  'bark_beetle': 0\n",
      "\n",
      "Preparing data for 5-Fold Cross-Validation (all objects as 'bark_beetle')...\n",
      "\n",
      "--- Processing CV Iteration 1/5 ---\n",
      "  Validation Fold: detection_fold1\n",
      "  Training Folds: detection_fold2, detection_fold3, detection_fold4, detection_fold5\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/ultralytics/cv_iteration_1\n",
      "  Processing training data for CV Iteration 1...\n",
      "    Processed 1640 image files (labels generated if objects found) from source train fold 'detection_fold2' in 14.62s.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Your Dataset ---\n",
    "\n",
    "# **IMPORTANT**: Modify these paths and names to match your actual dataset and desired output.\n",
    "# Example for a Linux-like environment:\n",
    "SOURCE_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/detection_folds_output\"\n",
    "BASE_DEST_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/ultralytics\"\n",
    "SOURCE_FOLD_NAMES_STR = \"detection_fold1,detection_fold2,detection_fold3,detection_fold4,detection_fold5\" # Comma-separated\n",
    "\n",
    "# Example for a Windows environment (use raw strings r\"...\" or double backslashes \\\\):\n",
    "# SOURCE_DIR = r\"C:\\Users\\YourUser\\Documents\\datasets\\my_original_beetle_data_folds\"\n",
    "# BASE_DEST_DIR = r\"C:\\Users\\YourUser\\Documents\\datasets\\yolo_kfold_bark_beetle_output\"\n",
    "# SOURCE_FOLD_NAMES_STR = \"beetle_fold_01,beetle_fold_02,beetle_fold_03,beetle_fold_04,beetle_fold_05\"\n",
    "\n",
    "\n",
    "# Optional: Control the number of parallel processes.\n",
    "# 'None' will default to the number of CPUs on your machine (os.cpu_count()).\n",
    "# You can set a specific number if needed, e.g., MAX_WORKERS = 4.\n",
    "# For I/O heavy tasks, sometimes more workers than CPUs can be beneficial,\n",
    "# but for CPU-bound tasks within processes, os.cpu_count() is a good start.\n",
    "import os # Import os here if you plan to use os.cpu_count() explicitly.\n",
    "MAX_WORKERS = 6 # Let Python's ProcessPoolExecutor decide based on os.cpu_count()\n",
    "# MAX_WORKERS = 4 # Or, set a specific number of workers\n",
    "\n",
    "\n",
    "# --- Run the Dataset Creation ---\n",
    "if __name__ == '__main__': # This condition is true when running a .py script,\n",
    "                           # but in Jupyter, cells run in a global scope related to the kernel.\n",
    "                           # It's often included for consistency but isn't strictly necessary\n",
    "                           # for just calling a function defined in a previous cell.\n",
    "                           # We'll call the function directly.\n",
    "\n",
    "    print(f\"Starting dataset creation with 'bark_beetle' as the single class:\")\n",
    "    print(f\"  Source Directory: {SOURCE_DIR}\")\n",
    "    print(f\"  Base Destination Directory: {BASE_DEST_DIR}\")\n",
    "    print(f\"  Source Fold Names: {SOURCE_FOLD_NAMES_STR.split(',')}\") # Show as a list for clarity\n",
    "    print(f\"  Max Workers for Parallelization: {MAX_WORKERS if MAX_WORKERS is not None else f'Default (likely {os.cpu_count()})'}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Make sure the function create_kfold_yolo_datasets is defined by running the cell above first!\n",
    "    create_kfold_yolo_datasets(\n",
    "        source_dir=SOURCE_DIR,\n",
    "        base_dest_dir=BASE_DEST_DIR,\n",
    "        source_fold_names_str=SOURCE_FOLD_NAMES_STR,\n",
    "        max_workers=MAX_WORKERS\n",
    "    )\n",
    "\n",
    "    print(\"\\nScript execution finished in this cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
