{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073e8535-f139-4024-b791-b0f591ceed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting COCO dataset creation for the TEST SET (Single Class: 'bark_beetle'):\n",
      "  Source Test Data Directory: /path/to/your/single_folder_test_data\n",
      "  Output COCO Test Directory: /path/to/your/output_coco_test_directory\n",
      "  Image Output Subfolder: 'data'\n",
      "  Max Workers for Parallelization: Default (likely 128)\n",
      "------------------------------\n",
      "\n",
      "PLEASE UPDATE 'SOURCE_TEST_DATA_DIR' and 'OUTPUT_COCO_TEST_DIR' before running the script!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "# from collections import OrderedDict # Not strictly needed for this version\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# --- COCO Bounding Box Conversion ---\n",
    "def convert_to_coco_bbox(points, image_height, image_width):\n",
    "    \"\"\"\n",
    "    Converts [[x1, y1], [x2, y2]] points to COCO bbox [x_min, y_min, width, height].\n",
    "    Clamps coordinates to be within image boundaries.\n",
    "    \"\"\"\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "\n",
    "    x_min_abs = float(min(x_coords))\n",
    "    y_min_abs = float(min(y_coords))\n",
    "    x_max_abs = float(max(x_coords))\n",
    "    y_max_abs = float(max(y_coords))\n",
    "\n",
    "    # Clamp to image boundaries\n",
    "    x_min_abs = max(0.0, x_min_abs)\n",
    "    y_min_abs = max(0.0, y_min_abs)\n",
    "    x_max_abs = min(float(image_width - 1), x_max_abs) # image_width is count, so max index is width-1\n",
    "    y_max_abs = min(float(image_height - 1), y_max_abs) # image_height is count, so max index is height-1\n",
    "    \n",
    "    # Ensure valid box dimensions\n",
    "    if x_min_abs >= x_max_abs or y_min_abs >= y_max_abs:\n",
    "        return None # Invalid box\n",
    "\n",
    "    width = x_max_abs - x_min_abs\n",
    "    height = y_max_abs - y_min_abs\n",
    "    \n",
    "    return [x_min_abs, y_min_abs, width, height]\n",
    "\n",
    "# --- Fixed Category Definition for COCO ---\n",
    "def get_fixed_coco_category_list(class_name=\"bark_beetle\", class_id=1):\n",
    "    \"\"\"Returns a COCO categories list for a single, fixed class.\"\"\"\n",
    "    print(f\"Defining fixed COCO category: ID: {class_id}, Name: {class_name}\")\n",
    "    return [{\n",
    "        \"id\": class_id,\n",
    "        \"name\": class_name,\n",
    "        \"supercategory\": class_name # Or a more general one if applicable\n",
    "    }]\n",
    "\n",
    "# --- Worker for processing one image-JSON pair for COCO (Single Class) ---\n",
    "def _process_single_image_to_coco_data_single_class(args_tuple):\n",
    "    \"\"\"\n",
    "    Processes one image and its JSON. All shapes are mapped to a single class name.\n",
    "    Returns dict with image_info and list of annotation_data (pre-ID assignment).\n",
    "    args_tuple: (img_filename_no_ext, source_data_path, new_img_filename_for_coco, fixed_class_name)\n",
    "    \"\"\"\n",
    "    img_filename_no_ext, source_data_path, new_img_filename_for_coco, fixed_class_name = args_tuple\n",
    "    \n",
    "    png_file = f\"{img_filename_no_ext}.png\"\n",
    "    json_file = f\"{img_filename_no_ext}.json\"\n",
    "\n",
    "    source_png_path = os.path.join(source_data_path, png_file)\n",
    "    source_json_path = os.path.join(source_data_path, json_file)\n",
    "\n",
    "    if not (os.path.exists(source_png_path) and os.path.exists(source_json_path)):\n",
    "        # print(f\"Warning (Worker): Missing PNG or JSON for {img_filename_no_ext} in {source_data_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(source_json_path, 'r') as f:\n",
    "            user_json_data = json.load(f)\n",
    "        \n",
    "        image_height = user_json_data.get(\"imageHeight\")\n",
    "        image_width = user_json_data.get(\"imageWidth\")\n",
    "\n",
    "        # If dimensions are not in JSON, try to get them from the image file\n",
    "        if image_height is None or image_width is None:\n",
    "            with Image.open(source_png_path) as img_pil:\n",
    "                pil_width, pil_height = img_pil.size\n",
    "            if image_width is None: image_width = pil_width\n",
    "            if image_height is None: image_height = pil_height\n",
    "        \n",
    "        if not image_height or not image_width:\n",
    "            # print(f\"Warning (Worker): Could not determine image dimensions for {source_png_path}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        image_info = {\n",
    "            \"file_name\": new_img_filename_for_coco, # This is the filename as it will be in COCO dataset\n",
    "            \"height\": int(image_height),\n",
    "            \"width\": int(image_width),\n",
    "            \"original_path\": source_png_path # Temp field for copying the file later\n",
    "        }\n",
    "        \n",
    "        annotations_data = []\n",
    "        for shape in user_json_data.get(\"shapes\", []):\n",
    "            points = shape.get(\"points\")\n",
    "            shape_type = shape.get(\"shape_type\")\n",
    "\n",
    "            # Assuming LabelMe style rectangle format [[x1,y1],[x2,y2]]\n",
    "            if not points or shape_type != \"rectangle\" or len(points) != 2:\n",
    "                # print(f\"Warning (Worker): Skipping non-rectangle or malformed shape in {source_json_path}\")\n",
    "                continue\n",
    "            \n",
    "            coco_bbox = convert_to_coco_bbox(points, image_height, image_width)\n",
    "            if coco_bbox:\n",
    "                annotations_data.append({\n",
    "                    \"category_name\": fixed_class_name, # Use the fixed class name\n",
    "                    \"bbox\": coco_bbox,\n",
    "                    \"area\": coco_bbox[2] * coco_bbox[3] # width * height\n",
    "                })\n",
    "        \n",
    "        # Include image even if it has no annotations, if needed (currently not forcing)\n",
    "        # if not annotations_data and not image_info.get('force_include_empty', False):\n",
    "        #     return None # Or handle as per requirements for empty images\n",
    "            \n",
    "        return {\"image_info\": image_info, \"annotations_data\": annotations_data, \"original_source_path\": source_png_path}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning (Worker): Error processing {source_png_path} or {source_json_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Function to create COCO dataset for a single test set ---\n",
    "def create_coco_test_dataset_single_class(\n",
    "    source_test_data_dir,\n",
    "    output_coco_test_dir,\n",
    "    fixed_class_name=\"bark_beetle\",\n",
    "    fixed_class_id=1,\n",
    "    max_workers=None,\n",
    "    image_output_folder_name=\"data\" # Subfolder name for images, e.g., \"data\" or \"images\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a COCO-formatted dataset for a single test set.\n",
    "    All objects are mapped to a single class.\n",
    "\n",
    "    Args:\n",
    "        source_test_data_dir (str): Path to the directory containing raw test .png images and .json files.\n",
    "        output_coco_test_dir (str): Path to the directory where the COCO-formatted test set will be saved.\n",
    "        fixed_class_name (str): The single class name to assign to all annotations.\n",
    "        fixed_class_id (int): The single class ID to assign.\n",
    "        max_workers (int, optional): Maximum number of worker processes. Defaults to os.cpu_count().\n",
    "        image_output_folder_name (str): Name of the subfolder within output_coco_test_dir for storing images.\n",
    "    \"\"\"\n",
    "    overall_start_time = time.time()\n",
    "    print(f\"\\nProcessing Test Dataset (COCO Format, Single Class: '{fixed_class_name}')...\")\n",
    "\n",
    "    if not os.path.isdir(source_test_data_dir):\n",
    "        print(f\"Error: Source test data directory '{source_test_data_dir}' not found.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(output_coco_test_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Get the fixed COCO category list\n",
    "    coco_categories = get_fixed_coco_category_list(class_name=fixed_class_name, class_id=fixed_class_id)\n",
    "    category_name_to_id = {cat['name']: cat['id'] for cat in coco_categories}\n",
    "\n",
    "    # 2. Define output paths\n",
    "    images_dest_dir = os.path.join(output_coco_test_dir, image_output_folder_name)\n",
    "    annotations_dest_dir = os.path.join(output_coco_test_dir, \"annotations\")\n",
    "    os.makedirs(images_dest_dir, exist_ok=True)\n",
    "    os.makedirs(annotations_dest_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"  Output images to: {images_dest_dir}\")\n",
    "    print(f\"  Output annotations to: {annotations_dest_dir}\")\n",
    "\n",
    "    # 3. Initialize COCO output structure\n",
    "    coco_output_data = {\n",
    "        \"info\": {\n",
    "            \"description\": f\"COCO-style Test Dataset (Single Class: {fixed_class_name})\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": datetime.date.today().year,\n",
    "            \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "        },\n",
    "        \"licenses\": [{\"name\": \"Placeholder License\", \"id\": 0, \"url\": \"\"}], # Add actual license if applicable\n",
    "        \"categories\": coco_categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    current_image_id = 1\n",
    "    current_annotation_id = 1\n",
    "    tasks_for_processing = []\n",
    "\n",
    "    # 4. Prepare tasks from the source test directory\n",
    "    image_basenames = sorted([\n",
    "        os.path.splitext(f)[0] for f in os.listdir(source_test_data_dir) \n",
    "        if f.lower().endswith(\".png\") and os.path.exists(os.path.join(source_test_data_dir, f\"{os.path.splitext(f)[0]}.json\"))\n",
    "    ])\n",
    "    \n",
    "    if not image_basenames:\n",
    "        print(f\"  No matching PNG/JSON pairs found in '{source_test_data_dir}'.\")\n",
    "        return\n",
    "\n",
    "    for img_basename in image_basenames:\n",
    "        # The filename for COCO dataset will be the original filename.\n",
    "        # It will be placed inside the `image_output_folder_name` directory.\n",
    "        new_img_filename_for_coco = f\"{img_basename}.png\" \n",
    "        tasks_for_processing.append(\n",
    "            (img_basename, source_test_data_dir, new_img_filename_for_coco, fixed_class_name)\n",
    "        )\n",
    "    \n",
    "    # 5. Process images and annotations\n",
    "    print(f\"  Found {len(tasks_for_processing)} images to process from '{source_test_data_dir}'...\")\n",
    "    processed_results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {\n",
    "            executor.submit(_process_single_image_to_coco_data_single_class, task_args): task_args \n",
    "            for task_args in tasks_for_processing\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    processed_results.append(result)\n",
    "            except Exception as exc:\n",
    "                task_args = future_to_task[future]\n",
    "                img_filename_no_ext = task_args[0]\n",
    "                print(f\"  Warning: Image '{img_filename_no_ext}.png' generated an exception during processing: {exc}\")\n",
    "\n",
    "    # 6. Aggregate results into COCO format\n",
    "    images_processed_count = 0\n",
    "    annotations_added_count = 0\n",
    "    for result_data in processed_results:\n",
    "        if not result_data or not result_data.get(\"image_info\"):\n",
    "            continue\n",
    "\n",
    "        # Copy image to the destination image folder\n",
    "        # result_data[\"image_info\"][\"file_name\"] is already set to \"basename.png\" by the worker\n",
    "        target_image_path = os.path.join(images_dest_dir, result_data[\"image_info\"][\"file_name\"])\n",
    "        try:\n",
    "            shutil.copy2(result_data[\"original_source_path\"], target_image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error copying image {result_data['original_source_path']} to {target_image_path}: {e}\")\n",
    "            continue # Skip this image if copy fails\n",
    "        \n",
    "        img_entry = result_data[\"image_info\"]\n",
    "        img_entry[\"id\"] = current_image_id\n",
    "        # The file_name in COCO should be just the filename (e.g., \"image1.png\").\n",
    "        # The annotation file will be in \"annotations/\" and images in \"data/\" (or \"images/\").\n",
    "        # Path relativity is handled by the COCO consumer based on this structure.\n",
    "        del img_entry[\"original_path\"] # Remove temporary path\n",
    "        coco_output_data[\"images\"].append(img_entry)\n",
    "        images_processed_count += 1\n",
    "        \n",
    "        for ann_data in result_data[\"annotations_data\"]:\n",
    "            if ann_data[\"category_name\"] not in category_name_to_id:\n",
    "                print(f\"  Logic Error: Fixed class name '{ann_data['category_name']}' not found in category map. Skipping annotation.\")\n",
    "                continue\n",
    "\n",
    "            ann_entry = {\n",
    "                \"id\": current_annotation_id,\n",
    "                \"image_id\": current_image_id, # Link to the current image\n",
    "                \"category_id\": category_name_to_id[ann_data[\"category_name\"]],\n",
    "                \"bbox\": ann_data[\"bbox\"],\n",
    "                \"area\": ann_data[\"area\"],\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": [] # Add segmentation if you have it, otherwise empty list for bbox\n",
    "            }\n",
    "            coco_output_data[\"annotations\"].append(ann_entry)\n",
    "            current_annotation_id += 1\n",
    "            annotations_added_count +=1\n",
    "        current_image_id += 1 # Increment for the next image\n",
    "        \n",
    "    # 7. Write the COCO JSON annotation file\n",
    "    output_json_filename = \"instances_test.json\"\n",
    "    output_json_path = os.path.join(annotations_dest_dir, output_json_filename)\n",
    "    try:\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(coco_output_data, f, indent=4)\n",
    "        processing_time = time.time() - overall_start_time\n",
    "        print(f\"\\n  Successfully created '{output_json_filename}' with {images_processed_count} images and {annotations_added_count} annotations.\")\n",
    "        print(f\"Test set processing complete in {processing_time:.2f} seconds!\")\n",
    "        print(f\"Test dataset is ready under: {output_coco_test_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error writing COCO JSON for test set '{output_json_filename}': {e}\")\n",
    "\n",
    "# --- Configuration and Execution for Test Set ---\n",
    "if __name__ == \"__main__\":\n",
    "    # **IMPORTANT**: Modify these paths and names to match your actual dataset and desired output.\n",
    "    \n",
    "    # Path to the single folder containing your raw test images (.png) and annotation files (.json)\n",
    "    # Example: \"/mnt/data/my_project/raw_test_images_and_json/\"\n",
    "    SOURCE_TEST_DATA_DIR = \"/path/to/your/single_folder_test_data\" \n",
    "    \n",
    "    # Path to the directory where the COCO-formatted test set will be saved.\n",
    "    # This directory will be created if it doesn't exist.\n",
    "    # Inside, \"data/\" (or \"images/\") and \"annotations/\" subfolders will be created.\n",
    "    # Example: \"/mnt/data/my_project/coco_formatted_test_set/\"\n",
    "    OUTPUT_COCO_TEST_DIR = \"/path/to/your/output_coco_test_directory\"\n",
    "\n",
    "    # Define the single class name and its ID (COCO typically starts IDs at 1)\n",
    "    FIXED_CLASS_NAME = \"bark_beetle\"  # Or your specific class name\n",
    "    FIXED_CLASS_ID = 1               # Ensure this ID is consistent if your model expects a specific ID\n",
    "\n",
    "    # Optional: Control the number of parallel processes for image processing\n",
    "    # Set to None to use all available CPU cores, or an integer for a specific number.\n",
    "    MAX_WORKERS = None # os.cpu_count()\n",
    "    # MAX_WORKERS = 4 # Example: use 4 worker processes\n",
    "\n",
    "    # Name for the subfolder where images will be copied within OUTPUT_COCO_TEST_DIR\n",
    "    IMAGE_OUTPUT_FOLDER_NAME = \"data\" # Common choices: \"data\", \"images\", \"test_images\"\n",
    "\n",
    "    # --- Run the Test Set Creation ---\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Starting COCO dataset creation for the TEST SET (Single Class: '{FIXED_CLASS_NAME}'):\")\n",
    "    print(f\"  Source Test Data Directory: {SOURCE_TEST_DATA_DIR}\")\n",
    "    print(f\"  Output COCO Test Directory: {OUTPUT_COCO_TEST_DIR}\")\n",
    "    print(f\"  Image Output Subfolder: '{IMAGE_OUTPUT_FOLDER_NAME}'\")\n",
    "    max_workers_display = MAX_WORKERS if MAX_WORKERS is not None else f'Default (likely {os.cpu_count()})'\n",
    "    print(f\"  Max Workers for Parallelization: {max_workers_display}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Before running, ensure SOURCE_TEST_DATA_DIR and OUTPUT_COCO_TEST_DIR are correctly set!\n",
    "    if SOURCE_TEST_DATA_DIR == \"/path/to/your/single_folder_test_data\" or \\\n",
    "       OUTPUT_COCO_TEST_DIR == \"/path/to/your/output_coco_test_directory\":\n",
    "        print(\"\\nPLEASE UPDATE 'SOURCE_TEST_DATA_DIR' and 'OUTPUT_COCO_TEST_DIR' before running the script!\")\n",
    "    else:\n",
    "        create_coco_test_dataset_single_class(\n",
    "            source_test_data_dir=SOURCE_TEST_DATA_DIR,\n",
    "            output_coco_test_dir=OUTPUT_COCO_TEST_DIR,\n",
    "            fixed_class_name=FIXED_CLASS_NAME,\n",
    "            fixed_class_id=FIXED_CLASS_ID,\n",
    "            max_workers=MAX_WORKERS,\n",
    "            image_output_folder_name=IMAGE_OUTPUT_FOLDER_NAME\n",
    "        )\n",
    "        print(\"\\nCOCO Test Set Script execution finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ba9902-0191-4ebe-8ebd-590c4f059ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting COCO dataset creation for the TEST SET (Single Class: 'bark_beetle'):\n",
      "  Source Test Data Directory: /blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output\n",
      "  Output COCO Test Directory: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/coco/test\n",
      "  Max Workers for Parallelization: 4\n",
      "------------------------------\n",
      "\n",
      "Processing Test Dataset (COCO Format, Single Class: 'bark_beetle')...\n",
      "Defining fixed COCO category: ID: 1, Name: bark_beetle\n",
      "  Output images to: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/coco/test/data\n",
      "  Output annotations to: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/coco/test/annotations\n",
      "  Found 2031 images to process from '/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output'...\n",
      "\n",
      "  Successfully created 'instances_test.json' with 2031 images and 16480 annotations.\n",
      "Test set processing complete in 95.37 seconds!\n",
      "Test dataset is ready under: /blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/coco/test\n",
      "\n",
      "COCO Test Set Script execution finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Previous K-Fold COCO Creation (Example - keep as is or run separately) ---\n",
    "# print(f\"Starting COCO dataset creation for Co-DETR with K-Fold CV (Single Class: '{FIXED_CLASS_NAME}'):\")\n",
    "# # ... (your existing k-fold setup and call) ...\n",
    "# create_kfold_coco_datasets_single_class(\n",
    "#     source_dir=SOURCE_DIR,\n",
    "#     base_dest_dir=BASE_DEST_DIR,\n",
    "#     source_fold_names_str=SOURCE_FOLD_NAMES_STR,\n",
    "#     fixed_class_name=FIXED_CLASS_NAME,\n",
    "#     fixed_class_id=FIXED_CLASS_ID,\n",
    "#     max_workers=MAX_WORKERS\n",
    "# )\n",
    "# print(\"\\nCOCO Single-Class K-Fold Script execution finished.\")\n",
    "\n",
    "# --- Configuration for Your TEST Dataset (Single Class COCO) ---\n",
    "# **IMPORTANT**: Modify these paths to match your actual test dataset.\n",
    "SOURCE_TEST_DATA_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output\"  # e.g., \"/blue/hulcr/gmarais/PhD/phase_1_data/raw_test_set\"\n",
    "OUTPUT_COCO_TEST_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/2_object_detection_phase_2/coco/test\" # Or any other desired output path\n",
    "\n",
    "# FIXED_CLASS_NAME and FIXED_CLASS_ID should be the same as used for training/validation\n",
    "FIXED_CLASS_NAME = \"bark_beetle\" # (already defined)\n",
    "FIXED_CLASS_ID = 1 # (already defined)\n",
    "\n",
    "# MAX_WORKERS can be the same or adjusted\n",
    "MAX_WORKERS = 4 # (already defined)\n",
    "\n",
    "# --- Run the Test Set Creation ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Starting COCO dataset creation for the TEST SET (Single Class: '{FIXED_CLASS_NAME}'):\")\n",
    "print(f\"  Source Test Data Directory: {SOURCE_TEST_DATA_DIR}\")\n",
    "print(f\"  Output COCO Test Directory: {OUTPUT_COCO_TEST_DIR}\")\n",
    "print(f\"  Max Workers for Parallelization: {MAX_WORKERS if MAX_WORKERS is not None else f'Default (likely {os.cpu_count()})'}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Ensure the new function create_coco_test_dataset_single_class is defined by running the cell with its definition first!\n",
    "create_coco_test_dataset_single_class(\n",
    "    source_test_data_dir=SOURCE_TEST_DATA_DIR,\n",
    "    output_coco_test_dir=OUTPUT_COCO_TEST_DIR,\n",
    "    fixed_class_name=FIXED_CLASS_NAME,\n",
    "    fixed_class_id=FIXED_CLASS_ID,\n",
    "    max_workers=MAX_WORKERS,\n",
    "    image_output_folder_name=\"data\" # You can change this to \"images\" if you prefer\n",
    ")\n",
    "\n",
    "print(\"\\nCOCO Test Set Script execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
