{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a394e5-50d1-4605-be4c-87fe92269574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting COCO dataset creation for the MULTI-CLASS TEST SET:\n",
      "  Source Test Data Directory: /blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output\n",
      "  Output COCO Test Directory: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/coco/test\n",
      "  Image Output Subfolder: 'data'\n",
      "  Max Workers for Parallelization: Default (likely 128)\n",
      "------------------------------\n",
      "\n",
      "Processing Test Dataset (COCO Format, Multi-Class)...\n",
      "Discovering COCO categories from the test set (parallelized)...\n",
      "Discovered 63 COCO categories in 0.78 seconds:\n",
      "  ID: 1, Name: Ambrosiodmus_minor\n",
      "  ID: 2, Name: Ambrosiophilus_atratus\n",
      "  ID: 3, Name: Anisandrus_dispar\n",
      "  ID: 4, Name: Anisandrus_sayi\n",
      "  ID: 5, Name: Cnestus_mutilatus\n",
      "  ID: 6, Name: Coccotrypes_carpophagus\n",
      "  ID: 7, Name: Coccotrypes_dactyliperda\n",
      "  ID: 8, Name: Coptoborus_ricini\n",
      "  ID: 9, Name: Cryptocarenus_heveae\n",
      "  ID: 10, Name: Ctonoxylon_hagedorn\n",
      "  ID: 11, Name: Cyclorhipidion_pelliculosum\n",
      "  ID: 12, Name: Dendroctonus_rufipennis\n",
      "  ID: 13, Name: Dendroctonus_terebrans\n",
      "  ID: 14, Name: Dendroctonus_valens\n",
      "  ID: 15, Name: Dryocoetes_autographus\n",
      "  ID: 16, Name: Euplatypus_compositus\n",
      "  ID: 17, Name: Euwallacea_fornicatus\n",
      "  ID: 18, Name: Euwallacea_perbrevis\n",
      "  ID: 19, Name: Euwallacea_validus\n",
      "  ID: 20, Name: Hylastes_porculus\n",
      "  ID: 21, Name: Hylastes_salebrosus\n",
      "  ID: 22, Name: Hylesinus_aculeatus\n",
      "  ID: 23, Name: Hylesinus_crenatus\n",
      "  ID: 24, Name: Hylesinus_toranio\n",
      "  ID: 25, Name: Hylesinus_varius\n",
      "  ID: 26, Name: Hylurgops_palliatus\n",
      "  ID: 27, Name: Hylurgus_ligniperda\n",
      "  ID: 28, Name: Hypothenemus_hampei\n",
      "  ID: 29, Name: Ips_acuminatus\n",
      "  ID: 30, Name: Ips_avulsus\n",
      "  ID: 31, Name: Ips_calligraphus\n",
      "  ID: 32, Name: Ips_duplicatus\n",
      "  ID: 33, Name: Ips_grandicollis\n",
      "  ID: 34, Name: Ips_sexdentatus\n",
      "  ID: 35, Name: Ips_typographus\n",
      "  ID: 36, Name: Monarthrum_fasciatum\n",
      "  ID: 37, Name: Monarthrum_mali\n",
      "  ID: 38, Name: Myoplatypus_flavicornis\n",
      "  ID: 39, Name: Orthotomicus_caelatus\n",
      "  ID: 40, Name: Orthotomicus_erosus\n",
      "  ID: 41, Name: Pagiocerus_frontalis\n",
      "  ID: 42, Name: Phloeosinus_dentatus\n",
      "  ID: 43, Name: Pityogenes_chalcographus\n",
      "  ID: 44, Name: Pityophthorus_juglandis\n",
      "  ID: 45, Name: Platypus_cylindrus\n",
      "  ID: 46, Name: Platypus_koryoensis\n",
      "  ID: 47, Name: Pycnarthrum_hispidium\n",
      "  ID: 48, Name: Scolytodes_glaber\n",
      "  ID: 49, Name: Scolytus_multistriatus\n",
      "  ID: 50, Name: Scolytus_schevyrewi\n",
      "  ID: 51, Name: Taphrorychus_bicolor\n",
      "  ID: 52, Name: Tomicus_destruens\n",
      "  ID: 53, Name: Trypodendron_domesticum\n",
      "  ID: 54, Name: Xyleborinus_saxesenii\n",
      "  ID: 55, Name: Xyleborus_affinis\n",
      "  ID: 56, Name: Xyleborus_celsus\n",
      "  ID: 57, Name: Xyleborus_ferrugineus\n",
      "  ID: 58, Name: Xyleborus_glabratus\n",
      "  ID: 59, Name: Xylosandrus_amputatus\n",
      "  ID: 60, Name: Xylosandrus_compactus\n",
      "  ID: 61, Name: Xylosandrus_crassiusculus\n",
      "  ID: 62, Name: Xylosandrus_germanus\n",
      "  ID: 63, Name: Xylosandrus_morigerus\n",
      "  Output images to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/coco/test/data\n",
      "  Output annotations to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/coco/test/annotations\n",
      "  Found 2031 images to process from '/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output'...\n",
      "\n",
      "  Successfully created 'instances_test.json' with 2031 images and 16480 annotations.\n",
      "Test set processing complete in 31.02 seconds!\n",
      "Test dataset is ready under: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/coco/test\n",
      "\n",
      "COCO Multi-Class Test Set Script execution finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# --- COCO Bounding Box Conversion ---\n",
    "def convert_to_coco_bbox(points, image_height, image_width):\n",
    "    \"\"\"\n",
    "    Converts [[x1, y1], [x2, y2]] points to COCO bbox [x_min, y_min, width, height].\n",
    "    Clamps coordinates to be within image boundaries.\n",
    "    \"\"\"\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "\n",
    "    x_min_abs = float(min(x_coords))\n",
    "    y_min_abs = float(min(y_coords))\n",
    "    x_max_abs = float(max(x_coords))\n",
    "    y_max_abs = float(max(y_coords))\n",
    "\n",
    "    x_min_abs = max(0.0, x_min_abs)\n",
    "    y_min_abs = max(0.0, y_min_abs)\n",
    "    x_max_abs = min(float(image_width - 1), x_max_abs)\n",
    "    y_max_abs = min(float(image_height - 1), y_max_abs)\n",
    "    \n",
    "    if x_min_abs >= x_max_abs or y_min_abs >= y_max_abs:\n",
    "        return None\n",
    "\n",
    "    width = x_max_abs - x_min_abs\n",
    "    height = y_max_abs - y_min_abs\n",
    "    \n",
    "    return [x_min_abs, y_min_abs, width, height]\n",
    "\n",
    "# --- Category Discovery for Test Set ---\n",
    "def _get_labels_from_single_json(json_path):\n",
    "    \"\"\"Helper function to extract labels from a single JSON file.\"\"\"\n",
    "    labels_in_file = set()\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for shape in data.get(\"shapes\", []): # Assuming 'shapes' contains the objects\n",
    "            label = shape.get(\"label\")\n",
    "            if label:\n",
    "                labels_in_file.add(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning (Category Discovery Worker): Error reading {json_path}: {e}\")\n",
    "    return labels_in_file\n",
    "\n",
    "def discover_coco_categories_for_test_set(source_test_data_dir, max_workers=None):\n",
    "    \"\"\"Scans the test data directory in parallel to discover unique class labels.\"\"\"\n",
    "    print(\"Discovering COCO categories from the test set (parallelized)...\")\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    json_file_paths = []\n",
    "    if not os.path.isdir(source_test_data_dir):\n",
    "        print(f\"Error (Category Discovery): Source directory '{source_test_data_dir}' not found.\")\n",
    "        return []\n",
    "\n",
    "    for item_name in os.listdir(source_test_data_dir):\n",
    "        if item_name.lower().endswith(\".json\"):\n",
    "            json_file_paths.append(os.path.join(source_test_data_dir, item_name))\n",
    "\n",
    "    if not json_file_paths:\n",
    "        print(\"Warning: No JSON files found in the test set for category discovery.\")\n",
    "        return []\n",
    "\n",
    "    unique_labels = set()\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_path = {executor.submit(_get_labels_from_single_json, path): path for path in json_file_paths}\n",
    "        for future in concurrent.futures.as_completed(future_to_path):\n",
    "            try:\n",
    "                labels_from_file = future.result()\n",
    "                unique_labels.update(labels_from_file)\n",
    "            except Exception as exc:\n",
    "                path = future_to_path[future]\n",
    "                print(f\"Warning (Category Discovery Main): Generated an exception for {path}: {exc}\")\n",
    "    \n",
    "    sorted_labels = sorted(list(unique_labels))\n",
    "    \n",
    "    categories_list = []\n",
    "    # COCO category IDs typically start from 1.\n",
    "    for i, label_name in enumerate(sorted_labels):\n",
    "        categories_list.append({\n",
    "            \"id\": i + 1, # Category ID\n",
    "            \"name\": label_name,\n",
    "            \"supercategory\": label_name # Or a more general supercategory if you have one\n",
    "        })\n",
    "    \n",
    "    discovery_time = time.time() - overall_start_time\n",
    "    if categories_list:\n",
    "        print(f\"Discovered {len(categories_list)} COCO categories in {discovery_time:.2f} seconds:\")\n",
    "        for cat in categories_list:\n",
    "            print(f\"  ID: {cat['id']}, Name: {cat['name']}\")\n",
    "    else:\n",
    "        print(f\"Warning: No categories discovered in the test set after parallel processing in {discovery_time:.2f} seconds.\")\n",
    "    return categories_list\n",
    "\n",
    "# --- Worker for processing one image-JSON pair (Multi-Class) ---\n",
    "def _process_single_image_to_coco_data_multiclass(args_tuple):\n",
    "    \"\"\"\n",
    "    Processes one image and its JSON, preserving original labels.\n",
    "    Returns dict with image_info and list of annotation_data (pre-ID assignment).\n",
    "    args_tuple: (img_filename_no_ext, source_data_path, new_img_filename_for_coco)\n",
    "    \"\"\"\n",
    "    img_filename_no_ext, source_data_path, new_img_filename_for_coco = args_tuple\n",
    "    \n",
    "    png_file = f\"{img_filename_no_ext}.png\"\n",
    "    json_file = f\"{img_filename_no_ext}.json\"\n",
    "\n",
    "    source_png_path = os.path.join(source_data_path, png_file)\n",
    "    source_json_path = os.path.join(source_data_path, json_file)\n",
    "\n",
    "    if not (os.path.exists(source_png_path) and os.path.exists(source_json_path)):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(source_json_path, 'r') as f:\n",
    "            user_json_data = json.load(f)\n",
    "        \n",
    "        image_height = user_json_data.get(\"imageHeight\")\n",
    "        image_width = user_json_data.get(\"imageWidth\")\n",
    "\n",
    "        if image_height is None or image_width is None:\n",
    "            with Image.open(source_png_path) as img_pil:\n",
    "                pil_width, pil_height = img_pil.size\n",
    "            if image_width is None: image_width = pil_width\n",
    "            if image_height is None: image_height = pil_height\n",
    "        \n",
    "        if not image_height or not image_width:\n",
    "            return None\n",
    "\n",
    "        image_info = {\n",
    "            \"file_name\": new_img_filename_for_coco,\n",
    "            \"height\": int(image_height),\n",
    "            \"width\": int(image_width),\n",
    "            \"original_path\": source_png_path \n",
    "        }\n",
    "        \n",
    "        annotations_data = []\n",
    "        for shape in user_json_data.get(\"shapes\", []):\n",
    "            original_label = shape.get(\"label\")\n",
    "            points = shape.get(\"points\")\n",
    "            shape_type = shape.get(\"shape_type\")\n",
    "\n",
    "            if not original_label or not points or shape_type != \"rectangle\" or len(points) != 2:\n",
    "                continue\n",
    "            \n",
    "            coco_bbox = convert_to_coco_bbox(points, image_height, image_width)\n",
    "            if coco_bbox:\n",
    "                annotations_data.append({\n",
    "                    \"category_name\": original_label, # Will be mapped to category_id later\n",
    "                    \"bbox\": coco_bbox,\n",
    "                    \"area\": coco_bbox[2] * coco_bbox[3]\n",
    "                })\n",
    "            \n",
    "        return {\"image_info\": image_info, \"annotations_data\": annotations_data, \"original_source_path\": source_png_path}\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Warning (Worker): Error processing {source_png_path} or {source_json_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Function to create COCO Test Dataset (Multi-Class) ---\n",
    "def create_coco_test_dataset_multiclass(\n",
    "    source_test_data_dir,\n",
    "    output_coco_test_dir,\n",
    "    max_workers=None,\n",
    "    image_output_folder_name=\"data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a COCO-formatted test dataset preserving original class labels.\n",
    "    \"\"\"\n",
    "    overall_start_time = time.time()\n",
    "    print(f\"\\nProcessing Test Dataset (COCO Format, Multi-Class)...\")\n",
    "\n",
    "    if not os.path.isdir(source_test_data_dir):\n",
    "        print(f\"Error: Source test data directory '{source_test_data_dir}' not found.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(output_coco_test_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Discover COCO categories from the test set\n",
    "    coco_categories = discover_coco_categories_for_test_set(source_test_data_dir, max_workers)\n",
    "    if not coco_categories:\n",
    "        print(\"Error: No categories discovered in the test set. Cannot proceed.\")\n",
    "        return\n",
    "    category_name_to_id = {cat['name']: cat['id'] for cat in coco_categories}\n",
    "\n",
    "    # 2. Define output paths\n",
    "    images_dest_dir = os.path.join(output_coco_test_dir, image_output_folder_name)\n",
    "    annotations_dest_dir = os.path.join(output_coco_test_dir, \"annotations\")\n",
    "    os.makedirs(images_dest_dir, exist_ok=True)\n",
    "    os.makedirs(annotations_dest_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"  Output images to: {images_dest_dir}\")\n",
    "    print(f\"  Output annotations to: {annotations_dest_dir}\")\n",
    "\n",
    "    # 3. Initialize COCO output structure\n",
    "    coco_output_data = {\n",
    "        \"info\": {\n",
    "            \"description\": f\"COCO-style Test Dataset (Multi-Class)\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": datetime.date.today().year,\n",
    "            \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "        },\n",
    "        \"licenses\": [{\"name\": \"Placeholder License\", \"id\": 0, \"url\": \"\"}],\n",
    "        \"categories\": coco_categories, # Use discovered categories\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    current_image_id = 1\n",
    "    current_annotation_id = 1\n",
    "    tasks_for_processing = []\n",
    "\n",
    "    # 4. Prepare tasks from the source test directory\n",
    "    image_basenames = sorted([\n",
    "        os.path.splitext(f)[0] for f in os.listdir(source_test_data_dir) \n",
    "        if f.lower().endswith(\".png\") and os.path.exists(os.path.join(source_test_data_dir, f\"{os.path.splitext(f)[0]}.json\"))\n",
    "    ])\n",
    "    \n",
    "    if not image_basenames:\n",
    "        print(f\"  No matching PNG/JSON pairs found in '{source_test_data_dir}'.\")\n",
    "        return\n",
    "\n",
    "    for img_basename in image_basenames:\n",
    "        new_img_filename_for_coco = f\"{img_basename}.png\" \n",
    "        tasks_for_processing.append(\n",
    "            (img_basename, source_test_data_dir, new_img_filename_for_coco)\n",
    "        )\n",
    "    \n",
    "    # 5. Process images and annotations\n",
    "    print(f\"  Found {len(tasks_for_processing)} images to process from '{source_test_data_dir}'...\")\n",
    "    processed_results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {\n",
    "            executor.submit(_process_single_image_to_coco_data_multiclass, task_args): task_args \n",
    "            for task_args in tasks_for_processing\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    processed_results.append(result)\n",
    "            except Exception as exc:\n",
    "                task_args = future_to_task[future]\n",
    "                img_filename_no_ext = task_args[0]\n",
    "                print(f\"  Warning: Image '{img_filename_no_ext}.png' generated an exception during processing: {exc}\")\n",
    "\n",
    "    # 6. Aggregate results into COCO format\n",
    "    images_processed_count = 0\n",
    "    annotations_added_count = 0\n",
    "    for result_data in processed_results:\n",
    "        if not result_data or not result_data.get(\"image_info\"):\n",
    "            continue\n",
    "\n",
    "        target_image_path = os.path.join(images_dest_dir, result_data[\"image_info\"][\"file_name\"])\n",
    "        try:\n",
    "            shutil.copy2(result_data[\"original_source_path\"], target_image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error copying image {result_data['original_source_path']} to {target_image_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        img_entry = result_data[\"image_info\"]\n",
    "        img_entry[\"id\"] = current_image_id\n",
    "        del img_entry[\"original_path\"]\n",
    "        coco_output_data[\"images\"].append(img_entry)\n",
    "        images_processed_count += 1\n",
    "        \n",
    "        for ann_data in result_data[\"annotations_data\"]:\n",
    "            category_name = ann_data[\"category_name\"]\n",
    "            if category_name not in category_name_to_id:\n",
    "                print(f\"  Warning: Category '{category_name}' found in annotation for image {img_entry['file_name']} but not in discovered categories. Skipping this annotation.\")\n",
    "                continue\n",
    "\n",
    "            ann_entry = {\n",
    "                \"id\": current_annotation_id,\n",
    "                \"image_id\": current_image_id,\n",
    "                \"category_id\": category_name_to_id[category_name], # Use mapped ID\n",
    "                \"bbox\": ann_data[\"bbox\"],\n",
    "                \"area\": ann_data[\"area\"],\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": [] \n",
    "            }\n",
    "            coco_output_data[\"annotations\"].append(ann_entry)\n",
    "            current_annotation_id += 1\n",
    "            annotations_added_count +=1\n",
    "        current_image_id += 1\n",
    "        \n",
    "    # 7. Write the COCO JSON annotation file\n",
    "    output_json_filename = \"instances_test.json\"\n",
    "    output_json_path = os.path.join(annotations_dest_dir, output_json_filename)\n",
    "    try:\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(coco_output_data, f, indent=4)\n",
    "        processing_time = time.time() - overall_start_time\n",
    "        print(f\"\\n  Successfully created '{output_json_filename}' with {images_processed_count} images and {annotations_added_count} annotations.\")\n",
    "        print(f\"Test set processing complete in {processing_time:.2f} seconds!\")\n",
    "        print(f\"Test dataset is ready under: {output_coco_test_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error writing COCO JSON for test set '{output_json_filename}': {e}\")\n",
    "\n",
    "# --- Configuration and Execution for Test Set (Multi-Class) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # **IMPORTANT**: Modify these paths to match your actual dataset and desired output.\n",
    "    \n",
    "    # Path to the single folder containing your raw test images (.png) and annotation files (.json)\n",
    "    SOURCE_TEST_DATA_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/test_set_output\" \n",
    "    \n",
    "    # Path to the directory where the COCO-formatted test set will be saved.\n",
    "    OUTPUT_COCO_TEST_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/coco/test\"\n",
    "\n",
    "    # Optional: Control the number of parallel processes\n",
    "    MAX_WORKERS = None # os.cpu_count()\n",
    "    # MAX_WORKERS = 4 \n",
    "\n",
    "    IMAGE_OUTPUT_FOLDER_NAME = \"data\" # Or \"images\", \"test_images\", etc.\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Starting COCO dataset creation for the MULTI-CLASS TEST SET:\")\n",
    "    print(f\"  Source Test Data Directory: {SOURCE_TEST_DATA_DIR}\")\n",
    "    print(f\"  Output COCO Test Directory: {OUTPUT_COCO_TEST_DIR}\")\n",
    "    print(f\"  Image Output Subfolder: '{IMAGE_OUTPUT_FOLDER_NAME}'\")\n",
    "    max_workers_display = MAX_WORKERS if MAX_WORKERS is not None else f'Default (likely {os.cpu_count()})'\n",
    "    print(f\"  Max Workers for Parallelization: {max_workers_display}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    if SOURCE_TEST_DATA_DIR == \"/path/to/your/single_folder_test_data_multiclass\" or \\\n",
    "       OUTPUT_COCO_TEST_DIR == \"/path/to/your/output_coco_test_directory_multiclass\":\n",
    "        print(\"\\nPLEASE UPDATE 'SOURCE_TEST_DATA_DIR' and 'OUTPUT_COCO_TEST_DIR' before running the script!\")\n",
    "    else:\n",
    "        create_coco_test_dataset_multiclass(\n",
    "            source_test_data_dir=SOURCE_TEST_DATA_DIR,\n",
    "            output_coco_test_dir=OUTPUT_COCO_TEST_DIR,\n",
    "            max_workers=MAX_WORKERS,\n",
    "            image_output_folder_name=IMAGE_OUTPUT_FOLDER_NAME\n",
    "        )\n",
    "        print(\"\\nCOCO Multi-Class Test Set Script execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
