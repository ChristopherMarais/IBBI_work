{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea49961b-3ef9-4723-81aa-dd4a8b097065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import yaml # For data.yaml\n",
    "from PIL import Image # To verify/get image dimensions if needed\n",
    "import concurrent.futures\n",
    "import time # For timing\n",
    "\n",
    "# --- Utility Functions (largely unchanged but crucial) ---\n",
    "def convert_yolo_format(image_width, image_height, points, class_id):\n",
    "    \"\"\"\n",
    "    Converts a single bounding box to YOLO format.\n",
    "    'points' is a list of two points [[x1, y1], [x2, y2]]\n",
    "    Returns a string in YOLO format: \"class_id x_center y_center width height\"\n",
    "    \"\"\"\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "\n",
    "    x_min_abs = min(x_coords)\n",
    "    y_min_abs = min(y_coords)\n",
    "    x_max_abs = max(x_coords)\n",
    "    y_max_abs = max(y_coords)\n",
    "\n",
    "    x_min_abs = max(0, x_min_abs)\n",
    "    y_min_abs = max(0, y_min_abs)\n",
    "    x_max_abs = min(image_width - 1, x_max_abs)\n",
    "    y_max_abs = min(image_height - 1, y_max_abs)\n",
    "\n",
    "    if x_min_abs >= x_max_abs or y_min_abs >= y_max_abs:\n",
    "        return None\n",
    "\n",
    "    box_width_abs = x_max_abs - x_min_abs\n",
    "    box_height_abs = y_max_abs - y_min_abs\n",
    "\n",
    "    x_center_abs = x_min_abs + box_width_abs / 2.0\n",
    "    y_center_abs = y_min_abs + box_height_abs / 2.0\n",
    "\n",
    "    x_center_norm = x_center_abs / image_width\n",
    "    y_center_norm = y_center_abs / image_height\n",
    "    width_norm = box_width_abs / image_width\n",
    "    height_norm = box_height_abs / image_height\n",
    "\n",
    "    return f\"{class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
    "\n",
    "# --- Parallelized Class Discovery ---\n",
    "def _get_labels_from_single_json(json_path):\n",
    "    \"\"\"Helper function to extract labels from a single JSON file.\"\"\"\n",
    "    labels_in_file = set()\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for shape in data.get(\"shapes\", []):\n",
    "            label = shape.get(\"label\")\n",
    "            if label:\n",
    "                labels_in_file.add(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning (Class Discovery Worker): Error reading {json_path}: {e}\")\n",
    "    return labels_in_file\n",
    "\n",
    "def discover_all_classes_parallel(source_root_dir, all_fold_names, max_workers=None):\n",
    "    \"\"\"Scans all specified folds in parallel to discover all unique class labels.\"\"\"\n",
    "    print(\"Discovering all class labels across all specified folds (parallelized)...\")\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    json_file_paths = []\n",
    "    for fold_name in all_fold_names:\n",
    "        current_fold_path = os.path.join(source_root_dir, fold_name)\n",
    "        if not os.path.isdir(current_fold_path):\n",
    "            print(f\"Warning (Class Discovery): Source fold '{current_fold_path}' not found. Skipping.\")\n",
    "            continue\n",
    "        for item_name in os.listdir(current_fold_path):\n",
    "            if item_name.lower().endswith(\".json\"):\n",
    "                json_file_paths.append(os.path.join(current_fold_path, item_name))\n",
    "\n",
    "    if not json_file_paths:\n",
    "        print(\"Warning: No JSON files found for class discovery.\")\n",
    "        return OrderedDict()\n",
    "\n",
    "    unique_labels = set()\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_path = {executor.submit(_get_labels_from_single_json, path): path for path in json_file_paths}\n",
    "        for future in concurrent.futures.as_completed(future_to_path):\n",
    "            try:\n",
    "                labels_from_file = future.result()\n",
    "                unique_labels.update(labels_from_file)\n",
    "            except Exception as exc:\n",
    "                path = future_to_path[future]\n",
    "                print(f\"Warning (Class Discovery Main): Generated an exception for {path}: {exc}\")\n",
    "    \n",
    "    sorted_labels = sorted(list(unique_labels))\n",
    "    master_class_to_id_map = OrderedDict((label, i) for i, label in enumerate(sorted_labels))\n",
    "    \n",
    "    discovery_time = time.time() - overall_start_time\n",
    "    if master_class_to_id_map:\n",
    "        print(f\"Discovered {len(master_class_to_id_map)} unique classes in {discovery_time:.2f} seconds:\")\n",
    "        for name, idx in master_class_to_id_map.items():\n",
    "            print(f\"  '{name}': {idx}\")\n",
    "    else:\n",
    "        print(f\"Warning: No classes discovered after parallel processing in {discovery_time:.2f} seconds.\")\n",
    "    return master_class_to_id_map\n",
    "\n",
    "# --- Parallelized File Processing for a Single Fold ---\n",
    "def _process_single_image_json_pair(args_tuple):\n",
    "    \"\"\"\n",
    "    Helper function to process one image-JSON pair.\n",
    "    Expected args_tuple: (img_filename_no_ext, source_fold_path, master_class_to_id_map,\n",
    "                         output_images_dir, output_labels_dir)\n",
    "    Returns: True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    img_filename_no_ext, source_fold_path, master_class_to_id_map, \\\n",
    "    output_images_dir, output_labels_dir = args_tuple\n",
    "\n",
    "    png_file = f\"{img_filename_no_ext}.png\"\n",
    "    json_file = f\"{img_filename_no_ext}.json\"\n",
    "\n",
    "    source_png_path = os.path.join(source_fold_path, png_file)\n",
    "    source_json_path = os.path.join(source_fold_path, json_file)\n",
    "\n",
    "    if not (os.path.exists(source_png_path) and os.path.exists(source_json_path)):\n",
    "        # print(f\"Warning (File Worker): Missing image or JSON for {img_filename_no_ext} in {source_fold_path}\")\n",
    "        return False # Silently fail for missing pairs to reduce noise if expected\n",
    "\n",
    "    dest_png_path = os.path.join(output_images_dir, png_file)\n",
    "    try:\n",
    "        shutil.copy2(source_png_path, dest_png_path)\n",
    "        with open(source_json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        # print(f\"Warning (File Worker): Error copying or reading JSON for {source_png_path}: {e}\")\n",
    "        if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "        return False\n",
    "\n",
    "    image_height = data.get(\"imageHeight\")\n",
    "    image_width = data.get(\"imageWidth\")\n",
    "\n",
    "    if image_height is None or image_width is None:\n",
    "        try:\n",
    "            with Image.open(source_png_path) as img:\n",
    "                image_width_pil, image_height_pil = img.size\n",
    "            if image_height is None: image_height = image_height_pil\n",
    "            if image_width is None: image_width = image_width_pil\n",
    "        except Exception:\n",
    "            if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "            return False\n",
    "            \n",
    "    if not image_height or not image_width: # Handles 0 or None\n",
    "        if os.path.exists(dest_png_path): os.remove(dest_png_path)\n",
    "        return False\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for shape in data.get(\"shapes\", []):\n",
    "        label_name = shape.get(\"label\")\n",
    "        points = shape.get(\"points\")\n",
    "        shape_type = shape.get(\"shape_type\")\n",
    "\n",
    "        if not label_name or not points or shape_type != \"rectangle\" or len(points) != 2:\n",
    "            continue\n",
    "        if label_name not in master_class_to_id_map:\n",
    "            # This should be rare if discovery is correct and data is consistent\n",
    "            # print(f\"Error (File Worker): Label '{label_name}' from {json_file} not in master map.\")\n",
    "            continue\n",
    "        \n",
    "        class_id = master_class_to_id_map[label_name]\n",
    "        yolo_str = convert_yolo_format(image_width, image_height, points, class_id)\n",
    "        if yolo_str:\n",
    "            yolo_annotations.append(yolo_str)\n",
    "\n",
    "    if yolo_annotations:\n",
    "        dest_label_path = os.path.join(output_labels_dir, f\"{img_filename_no_ext}.txt\")\n",
    "        with open(dest_label_path, 'w') as f_label:\n",
    "            f_label.write(\"\\n\".join(yolo_annotations) + \"\\n\")\n",
    "        return True\n",
    "    elif os.path.exists(dest_png_path): # Image copied, but no valid annotations\n",
    "        # Optionally remove images if they have no annotations\n",
    "        # os.remove(dest_png_path)\n",
    "        # print(f\"Note (File Worker): No annotations for {png_file}, but image was copied.\")\n",
    "        return False # Count as not fully processed if no labels\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_single_fold_for_yolo_parallel(source_fold_path, image_basenames_in_fold,\n",
    "                                          master_class_to_id_map,\n",
    "                                          output_images_dir, output_labels_dir, max_workers=None):\n",
    "    \"\"\"Processes files from a single source fold in parallel.\"\"\"\n",
    "    processed_count = 0\n",
    "    \n",
    "    tasks = []\n",
    "    for img_basename in image_basenames_in_fold:\n",
    "        tasks.append((img_basename, source_fold_path, master_class_to_id_map,\n",
    "                      output_images_dir, output_labels_dir))\n",
    "\n",
    "    if not tasks:\n",
    "        return 0\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(_process_single_image_json_pair, task_args): task_args for task_args in tasks}\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            try:\n",
    "                if future.result(): # If _process_single_image_json_pair returned True\n",
    "                    processed_count += 1\n",
    "            except Exception as exc:\n",
    "                task_args_failed = future_to_task[future]\n",
    "                # print(f\"Warning (Fold Processor): Task for {task_args_failed[0]} generated an exception: {exc}\")\n",
    "                pass # Silently continue, or log more verbosely\n",
    "    return processed_count\n",
    "\n",
    "# --- Main Orchestrator Function for Jupyter Notebook ---\n",
    "def create_kfold_yolo_datasets(source_dir, base_dest_dir, source_fold_names_str, max_workers=None):\n",
    "    \"\"\"\n",
    "    Main function to create k-fold cross-validation datasets in YOLO format.\n",
    "    Designed to be called from a Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    all_original_fold_names = [name.strip() for name in source_fold_names_str.split(',') if name.strip()]\n",
    "\n",
    "    if not all_original_fold_names or len(all_original_fold_names) < 2:\n",
    "        print(\"Error: Please provide at least two source fold names for cross-validation.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print(f\"Error: Source directory '{source_dir}' not found.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(base_dest_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Discover all classes globally first (parallelized)\n",
    "    master_class_to_id_map = discover_all_classes_parallel(source_dir, all_original_fold_names, max_workers)\n",
    "    if not master_class_to_id_map:\n",
    "        print(\"Error: No classes were found in any of the specified folds. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    num_cv_folds = len(all_original_fold_names)\n",
    "    print(f\"\\nPreparing data for {num_cv_folds}-Fold Cross-Validation...\")\n",
    "\n",
    "    # 2. Loop for each CV iteration\n",
    "    for i in range(num_cv_folds):\n",
    "        cv_iteration_start_time = time.time()\n",
    "        current_val_fold_name = all_original_fold_names[i]\n",
    "        current_train_fold_names = [f_name for idx, f_name in enumerate(all_original_fold_names) if idx != i]\n",
    "\n",
    "        cv_iteration_dir_name = f\"cv_iteration_{i+1}\"\n",
    "        current_cv_split_output_root = os.path.join(base_dest_dir, cv_iteration_dir_name)\n",
    "\n",
    "        print(f\"\\n--- Processing CV Iteration {i+1}/{num_cv_folds} ---\")\n",
    "        print(f\"  Validation Fold: {current_val_fold_name}\")\n",
    "        print(f\"  Training Folds: {', '.join(current_train_fold_names)}\")\n",
    "        print(f\"  Output to: {current_cv_split_output_root}\")\n",
    "\n",
    "        train_images_dir = os.path.join(current_cv_split_output_root, \"images\", \"train\")\n",
    "        train_labels_dir = os.path.join(current_cv_split_output_root, \"labels\", \"train\")\n",
    "        val_images_dir = os.path.join(current_cv_split_output_root, \"images\", \"val\")\n",
    "        val_labels_dir = os.path.join(current_cv_split_output_root, \"labels\", \"val\")\n",
    "\n",
    "        os.makedirs(train_images_dir, exist_ok=True)\n",
    "        os.makedirs(train_labels_dir, exist_ok=True)\n",
    "        os.makedirs(val_images_dir, exist_ok=True)\n",
    "        os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "        # --- Process Training Folds for this CV Iteration (Parallel within each source fold) ---\n",
    "        print(f\"  Processing training data for CV Iteration {i+1}...\")\n",
    "        total_train_images_for_cv_iter = 0\n",
    "        for train_fold_name in current_train_fold_names:\n",
    "            fold_proc_start_time = time.time()\n",
    "            source_fold_path = os.path.join(source_dir, train_fold_name)\n",
    "            if not os.path.isdir(source_fold_path):\n",
    "                print(f\"  Warning: Training source fold '{source_fold_path}' not found. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            image_basenames = {os.path.splitext(f)[0] for f in os.listdir(source_fold_path) if f.lower().endswith(\".png\")}\n",
    "            if not image_basenames:\n",
    "                print(f\"  No PNG images found in training source fold '{source_fold_path}'.\")\n",
    "                continue\n",
    "                \n",
    "            count = process_single_fold_for_yolo_parallel(\n",
    "                source_fold_path, list(image_basenames), master_class_to_id_map,\n",
    "                train_images_dir, train_labels_dir, max_workers\n",
    "            )\n",
    "            total_train_images_for_cv_iter += count\n",
    "            fold_proc_time = time.time() - fold_proc_start_time\n",
    "            print(f\"    Processed {count} images from source train fold '{train_fold_name}' in {fold_proc_time:.2f}s.\")\n",
    "        print(f\"  Total training images for CV Iteration {i+1}: {total_train_images_for_cv_iter}\")\n",
    "\n",
    "        # --- Process Validation Fold for this CV Iteration (Parallel within the source fold) ---\n",
    "        print(f\"  Processing validation data for CV Iteration {i+1}...\")\n",
    "        total_val_images_for_cv_iter = 0\n",
    "        source_val_fold_path = os.path.join(source_dir, current_val_fold_name)\n",
    "        if not os.path.isdir(source_val_fold_path):\n",
    "            print(f\"  Warning: Validation source fold '{source_val_fold_path}' not found. Skipping val set for this iter.\")\n",
    "        else:\n",
    "            fold_proc_start_time = time.time()\n",
    "            image_basenames_val = {os.path.splitext(f)[0] for f in os.listdir(source_val_fold_path) if f.lower().endswith(\".png\")}\n",
    "            if not image_basenames_val:\n",
    "                print(f\"  No PNG images found in validation source fold '{source_val_fold_path}'.\")\n",
    "            else:\n",
    "                count_val = process_single_fold_for_yolo_parallel(\n",
    "                    source_val_fold_path, list(image_basenames_val), master_class_to_id_map,\n",
    "                    val_images_dir, val_labels_dir, max_workers\n",
    "                )\n",
    "                total_val_images_for_cv_iter = count_val\n",
    "                fold_proc_time = time.time() - fold_proc_start_time\n",
    "                print(f\"    Processed {count_val} images from source validation fold '{current_val_fold_name}' in {fold_proc_time:.2f}s.\")\n",
    "        print(f\"  Total validation images for CV Iteration {i+1}: {total_val_images_for_cv_iter}\")\n",
    "\n",
    "        # --- Create data.yaml for this CV Iteration ---\n",
    "        data_yaml_content = {\n",
    "            'path': os.path.abspath(current_cv_split_output_root),\n",
    "            'train': os.path.join('images', 'train'),\n",
    "            'val': os.path.join('images', 'val'),\n",
    "            'nc': len(master_class_to_id_map),\n",
    "            'names': list(master_class_to_id_map.keys())\n",
    "        }\n",
    "        data_yaml_path = os.path.join(current_cv_split_output_root, \"data.yaml\")\n",
    "        try:\n",
    "            with open(data_yaml_path, 'w') as f:\n",
    "                yaml.dump(data_yaml_content, f, sort_keys=False, default_flow_style=False)\n",
    "            cv_iteration_time = time.time() - cv_iteration_start_time\n",
    "            print(f\"  Successfully created 'data.yaml' for CV Iteration {i+1}. Iteration took {cv_iteration_time:.2f}s.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error writing data.yaml for CV Iteration {i+1}: {e}\")\n",
    "\n",
    "    total_script_time = time.time() - overall_start_time\n",
    "    print(f\"\\n{num_cv_folds}-Fold Cross-Validation dataset preparation complete in {total_script_time:.2f} seconds!\")\n",
    "    print(f\"All CV iteration datasets are ready under: {base_dest_dir}\")\n",
    "\n",
    "# To run this in a Jupyter Notebook cell:\n",
    "\n",
    "# 1. Make sure you have PyYAML installed: pip install PyYAML Pillow\n",
    "# 2. Define your configuration variables in the cell:\n",
    "#\n",
    "# SOURCE_DIR = \"/path/to/your/original_dataset_with_folds\"  # e.g., \"/mnt/my_original_data\"\n",
    "# BASE_DEST_DIR = \"/path/to/your_yolo_kfold_datasets_output\" # e.g., \"/mnt/yolo_5fold_datasets_parallel\"\n",
    "# SOURCE_FOLD_NAMES_STR = \"original_fold_A,original_fold_B,original_fold_C,original_fold_D,original_fold_E\" # Comma-separated\n",
    "#\n",
    "# # Optional: Set max_workers for parallel processing. None uses os.cpu_count().\n",
    "# # For I/O bound tasks, you can sometimes benefit from more workers than CPUs.\n",
    "# # For CPU bound inside processes, os.cpu_count() is a good default.\n",
    "# MAX_WORKERS = None # or os.cpu_count() or a specific number like 4 or 8\n",
    "#\n",
    "# # 3. Call the main function:\n",
    "# if __name__ == '__main__': # This check is good practice, though not strictly needed if only run in a cell\n",
    "#    # Example of how to run it directly for testing (if not in Jupyter)\n",
    "#    # For Jupyter, you'd just define the variables above and then call:\n",
    "#    # create_kfold_yolo_datasets(SOURCE_DIR, BASE_DEST_DIR, SOURCE_FOLD_NAMES_STR, MAX_WORKERS)\n",
    "#    \n",
    "#    # --- EXAMPLE USAGE FOR JUPYTER (after defining variables above) ---\n",
    "#    # print(f\"Using source: {SOURCE_DIR}\")\n",
    "#    # print(f\"Using destination: {BASE_DEST_DIR}\")\n",
    "#    # print(f\"Using folds: {SOURCE_FOLD_NAMES_STR}\")\n",
    "#    # print(f\"Max workers: {MAX_WORKERS if MAX_WORKERS is not None else 'Default (os.cpu_count())'}\")\n",
    "#    #\n",
    "#    # create_kfold_yolo_datasets(SOURCE_DIR, BASE_DEST_DIR, SOURCE_FOLD_NAMES_STR, max_workers=MAX_WORKERS)\n",
    "#    pass # Pass here, as the actual call would be made directly in the notebook cell after defining vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d1437d-a4d4-4cae-85bb-ee4ef2480a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation with the following parameters:\n",
      "  Source Directory: /blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/classification_folds_output\n",
      "  Base Destination Directory: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics\n",
      "  Source Fold Names: fold1,fold2,fold3,fold4,fold5\n",
      "  Max Workers for Parallelization: 6\n",
      "------------------------------\n",
      "Discovering all class labels across all specified folds (parallelized)...\n",
      "Discovered 63 unique classes in 1.62 seconds:\n",
      "  'Ambrosiodmus_minor': 0\n",
      "  'Ambrosiophilus_atratus': 1\n",
      "  'Anisandrus_dispar': 2\n",
      "  'Anisandrus_sayi': 3\n",
      "  'Cnestus_mutilatus': 4\n",
      "  'Coccotrypes_carpophagus': 5\n",
      "  'Coccotrypes_dactyliperda': 6\n",
      "  'Coptoborus_ricini': 7\n",
      "  'Cryptocarenus_heveae': 8\n",
      "  'Ctonoxylon_hagedorn': 9\n",
      "  'Cyclorhipidion_pelliculosum': 10\n",
      "  'Dendroctonus_rufipennis': 11\n",
      "  'Dendroctonus_terebrans': 12\n",
      "  'Dendroctonus_valens': 13\n",
      "  'Dryocoetes_autographus': 14\n",
      "  'Euplatypus_compositus': 15\n",
      "  'Euwallacea_fornicatus': 16\n",
      "  'Euwallacea_perbrevis': 17\n",
      "  'Euwallacea_validus': 18\n",
      "  'Hylastes_porculus': 19\n",
      "  'Hylastes_salebrosus': 20\n",
      "  'Hylesinus_aculeatus': 21\n",
      "  'Hylesinus_crenatus': 22\n",
      "  'Hylesinus_toranio': 23\n",
      "  'Hylesinus_varius': 24\n",
      "  'Hylurgops_palliatus': 25\n",
      "  'Hylurgus_ligniperda': 26\n",
      "  'Hypothenemus_hampei': 27\n",
      "  'Ips_acuminatus': 28\n",
      "  'Ips_avulsus': 29\n",
      "  'Ips_calligraphus': 30\n",
      "  'Ips_duplicatus': 31\n",
      "  'Ips_grandicollis': 32\n",
      "  'Ips_sexdentatus': 33\n",
      "  'Ips_typographus': 34\n",
      "  'Monarthrum_fasciatum': 35\n",
      "  'Monarthrum_mali': 36\n",
      "  'Myoplatypus_flavicornis': 37\n",
      "  'Orthotomicus_caelatus': 38\n",
      "  'Orthotomicus_erosus': 39\n",
      "  'Pagiocerus_frontalis': 40\n",
      "  'Phloeosinus_dentatus': 41\n",
      "  'Pityogenes_chalcographus': 42\n",
      "  'Pityophthorus_juglandis': 43\n",
      "  'Platypus_cylindrus': 44\n",
      "  'Platypus_koryoensis': 45\n",
      "  'Pycnarthrum_hispidium': 46\n",
      "  'Scolytodes_glaber': 47\n",
      "  'Scolytus_multistriatus': 48\n",
      "  'Scolytus_schevyrewi': 49\n",
      "  'Taphrorychus_bicolor': 50\n",
      "  'Tomicus_destruens': 51\n",
      "  'Trypodendron_domesticum': 52\n",
      "  'Xyleborinus_saxesenii': 53\n",
      "  'Xyleborus_affinis': 54\n",
      "  'Xyleborus_celsus': 55\n",
      "  'Xyleborus_ferrugineus': 56\n",
      "  'Xyleborus_glabratus': 57\n",
      "  'Xylosandrus_amputatus': 58\n",
      "  'Xylosandrus_compactus': 59\n",
      "  'Xylosandrus_crassiusculus': 60\n",
      "  'Xylosandrus_germanus': 61\n",
      "  'Xylosandrus_morigerus': 62\n",
      "\n",
      "Preparing data for 5-Fold Cross-Validation...\n",
      "\n",
      "--- Processing CV Iteration 1/5 ---\n",
      "  Validation Fold: fold1\n",
      "  Training Folds: fold2, fold3, fold4, fold5\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_1\n",
      "  Processing training data for CV Iteration 1...\n",
      "    Processed 2302 images from source train fold 'fold2' in 15.05s.\n",
      "    Processed 2301 images from source train fold 'fold3' in 16.05s.\n",
      "    Processed 2301 images from source train fold 'fold4' in 16.33s.\n",
      "    Processed 2301 images from source train fold 'fold5' in 15.31s.\n",
      "  Total training images for CV Iteration 1: 9205\n",
      "  Processing validation data for CV Iteration 1...\n",
      "    Processed 2302 images from source validation fold 'fold1' in 86.15s.\n",
      "  Total validation images for CV Iteration 1: 2302\n",
      "  Successfully created 'data.yaml' for CV Iteration 1. Iteration took 148.89s.\n",
      "\n",
      "--- Processing CV Iteration 2/5 ---\n",
      "  Validation Fold: fold2\n",
      "  Training Folds: fold1, fold3, fold4, fold5\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_2\n",
      "  Processing training data for CV Iteration 2...\n",
      "    Processed 2302 images from source train fold 'fold1' in 5.85s.\n",
      "    Processed 2301 images from source train fold 'fold3' in 33.27s.\n",
      "    Processed 2301 images from source train fold 'fold4' in 12.02s.\n",
      "    Processed 2301 images from source train fold 'fold5' in 17.86s.\n",
      "  Total training images for CV Iteration 2: 9205\n",
      "  Processing validation data for CV Iteration 2...\n",
      "    Processed 2302 images from source validation fold 'fold2' in 121.36s.\n",
      "  Total validation images for CV Iteration 2: 2302\n",
      "  Successfully created 'data.yaml' for CV Iteration 2. Iteration took 190.38s.\n",
      "\n",
      "--- Processing CV Iteration 3/5 ---\n",
      "  Validation Fold: fold3\n",
      "  Training Folds: fold1, fold2, fold4, fold5\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_3\n",
      "  Processing training data for CV Iteration 3...\n",
      "    Processed 2302 images from source train fold 'fold1' in 18.65s.\n",
      "    Processed 2302 images from source train fold 'fold2' in 9.60s.\n",
      "    Processed 2301 images from source train fold 'fold4' in 25.02s.\n",
      "    Processed 2301 images from source train fold 'fold5' in 127.56s.\n",
      "  Total training images for CV Iteration 3: 9206\n",
      "  Processing validation data for CV Iteration 3...\n",
      "    Processed 2301 images from source validation fold 'fold3' in 14.73s.\n",
      "  Total validation images for CV Iteration 3: 2301\n",
      "  Successfully created 'data.yaml' for CV Iteration 3. Iteration took 195.63s.\n",
      "\n",
      "--- Processing CV Iteration 4/5 ---\n",
      "  Validation Fold: fold4\n",
      "  Training Folds: fold1, fold2, fold3, fold5\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_4\n",
      "  Processing training data for CV Iteration 4...\n",
      "    Processed 2302 images from source train fold 'fold1' in 130.27s.\n",
      "    Processed 2302 images from source train fold 'fold2' in 16.15s.\n",
      "    Processed 2301 images from source train fold 'fold3' in 49.66s.\n",
      "    Processed 2301 images from source train fold 'fold5' in 106.23s.\n",
      "  Total training images for CV Iteration 4: 9206\n",
      "  Processing validation data for CV Iteration 4...\n",
      "    Processed 2301 images from source validation fold 'fold4' in 15.61s.\n",
      "  Total validation images for CV Iteration 4: 2301\n",
      "  Successfully created 'data.yaml' for CV Iteration 4. Iteration took 318.06s.\n",
      "\n",
      "--- Processing CV Iteration 5/5 ---\n",
      "  Validation Fold: fold5\n",
      "  Training Folds: fold1, fold2, fold3, fold4\n",
      "  Output to: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_5\n",
      "  Processing training data for CV Iteration 5...\n",
      "    Processed 2302 images from source train fold 'fold1' in 146.61s.\n",
      "    Processed 2302 images from source train fold 'fold2' in 108.21s.\n",
      "    Processed 2301 images from source train fold 'fold3' in 14.05s.\n",
      "    Processed 2301 images from source train fold 'fold4' in 142.86s.\n",
      "  Total training images for CV Iteration 5: 9206\n",
      "  Processing validation data for CV Iteration 5...\n",
      "    Processed 2301 images from source validation fold 'fold5' in 16.60s.\n",
      "  Total validation images for CV Iteration 5: 2301\n",
      "  Successfully created 'data.yaml' for CV Iteration 5. Iteration took 428.46s.\n",
      "\n",
      "5-Fold Cross-Validation dataset preparation complete in 1283.05 seconds!\n",
      "All CV iteration datasets are ready under: /blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Your Dataset ---\n",
    "SOURCE_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/1_data_splitting/classification_folds_output\"  # CHANGE THIS\n",
    "BASE_DEST_DIR = \"/blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics\" # CHANGE THIS\n",
    "SOURCE_FOLD_NAMES_STR = \"fold1,fold2,fold3,fold4,fold5\" # CHANGE THIS\n",
    "\n",
    "# Optional: Control the number of parallel processes\n",
    "# None will default to the number of CPUs on your machine.\n",
    "# You might want to experiment with this value.\n",
    "MAX_WORKERS = 6 # os.cpu_count() can also be explicitly used here. For instance, if os.cpu_count() is not available, use MAX_WORKERS = 4\n",
    "# import os # if you want to use os.cpu_count() explicitly\n",
    "# MAX_WORKERS = os.cpu_count()\n",
    "\n",
    "\n",
    "# --- Run the Dataset Creation ---\n",
    "print(f\"Starting dataset creation with the following parameters:\")\n",
    "print(f\"  Source Directory: {SOURCE_DIR}\")\n",
    "print(f\"  Base Destination Directory: {BASE_DEST_DIR}\")\n",
    "print(f\"  Source Fold Names: {SOURCE_FOLD_NAMES_STR}\")\n",
    "print(f\"  Max Workers for Parallelization: {MAX_WORKERS if MAX_WORKERS is not None else 'Default (os.cpu_count())'}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "create_kfold_yolo_datasets(SOURCE_DIR, BASE_DEST_DIR, SOURCE_FOLD_NAMES_STR, max_workers=MAX_WORKERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
