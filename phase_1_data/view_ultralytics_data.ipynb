{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38ce8d-9462-4e11-b32c-24f5e9018ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def load_yaml(yaml_path):\n",
    "    \"\"\"Loads a YAML file.\"\"\"\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def denormalize_bbox(bbox_norm, img_width, img_height):\n",
    "    \"\"\"Converts normalized bounding box coordinates to absolute pixel values.\"\"\"\n",
    "    x_center_norm, y_center_norm, width_norm, height_norm = bbox_norm\n",
    "    x_center = x_center_norm * img_width\n",
    "    y_center = y_center_norm * img_height\n",
    "    width = width_norm * img_width\n",
    "    height = height_norm * img_height\n",
    "    \n",
    "    x_min = int(x_center - width / 2)\n",
    "    y_min = int(y_center - height / 2)\n",
    "    x_max = int(x_center + width / 2)\n",
    "    y_max = int(y_center + height / 2)\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def visualize_dataset_sample(data_yaml_path, num_images_to_show=3, dataset_split='train'):\n",
    "    \"\"\"\n",
    "    Visualizes a few sample images with their bounding boxes and class labels\n",
    "    from an Ultralytics-formatted object detection dataset.\n",
    "\n",
    "    Args:\n",
    "        data_yaml_path (str): Path to the data.yaml file.\n",
    "        num_images_to_show (int): Number of random images to display.\n",
    "        dataset_split (str): The dataset split to use ('train', 'val', or 'test').\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to visualize {num_images_to_show} images from the '{dataset_split}' split.\")\n",
    "    print(f\"Loading dataset configuration from: {data_yaml_path}\")\n",
    "\n",
    "    try:\n",
    "        config = load_yaml(data_yaml_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load or parse {data_yaml_path}. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    class_names = config.get('names')\n",
    "    if not class_names:\n",
    "        print(f\"Error: 'names' (class names dictionary/list) not found in {data_yaml_path}.\")\n",
    "        return\n",
    "    print(f\"Class names loaded: {class_names}\")\n",
    "\n",
    "    yaml_file_directory = os.path.dirname(os.path.abspath(data_yaml_path))\n",
    "    \n",
    "    # Determine the dataset root directory.\n",
    "    # 'path' in YAML is the dataset root, typically relative to the YAML file's location.\n",
    "    dataset_root_config_path = config.get('path') \n",
    "    if dataset_root_config_path:\n",
    "        # If 'path' is absolute, use it. Otherwise, resolve it relative to the YAML file.\n",
    "        if os.path.isabs(dataset_root_config_path):\n",
    "            dataset_root_abs = dataset_root_config_path\n",
    "        else:\n",
    "            dataset_root_abs = os.path.abspath(os.path.join(yaml_file_directory, dataset_root_config_path))\n",
    "    else:\n",
    "        # If 'path' is not in YAML, assume train/val paths are relative to YAML dir or absolute.\n",
    "        dataset_root_abs = yaml_file_directory \n",
    "        print(\"Warning: 'path' key not found in data.yaml. Assuming paths for dataset splits are absolute or relative to the YAML file's directory.\")\n",
    "\n",
    "    if dataset_root_config_path and not os.path.isdir(dataset_root_abs): # Only error if 'path' was specified and not found\n",
    "        print(f\"Error: Dataset root directory '{dataset_root_abs}' (derived from 'path: {dataset_root_config_path}') does not exist.\")\n",
    "        return\n",
    "    print(f\"Interpreted dataset root (or base for resolving paths): {dataset_root_abs}\")\n",
    "    \n",
    "    # Get the path for the image directory of the chosen split (e.g., 'images/train' or 'train')\n",
    "    image_dir_relative_or_abs = config.get(dataset_split)\n",
    "    if not image_dir_relative_or_abs:\n",
    "        print(f\"Error: Path for dataset split '{dataset_split}' not found in {data_yaml_path}.\")\n",
    "        return\n",
    "\n",
    "    # Construct the full image directory path\n",
    "    if os.path.isabs(image_dir_relative_or_abs):\n",
    "        full_image_dir = image_dir_relative_or_abs\n",
    "    else:\n",
    "        # If 'path' was defined, image_dir_relative_or_abs is relative to dataset_root_abs.\n",
    "        # Otherwise, it's relative to yaml_file_directory (which is dataset_root_abs in that case).\n",
    "        full_image_dir = os.path.join(dataset_root_abs, image_dir_relative_or_abs)\n",
    "    \n",
    "    full_image_dir = os.path.abspath(full_image_dir)\n",
    "    print(f\"Constructed full image directory: {full_image_dir}\")\n",
    "\n",
    "    # Infer the label directory path\n",
    "    # Standard structure: replace 'images' with 'labels' in the path.\n",
    "    # e.g., /path/to/dataset/images/train -> /path/to/dataset/labels/train\n",
    "    path_parts = list(os.path.split(full_image_dir)) # Robustly split path\n",
    "    full_label_dir = \"\"\n",
    "    try:\n",
    "        # Find the 'images' directory component and replace it with 'labels'\n",
    "        # This assumes a structure like .../dataset_name/images/split_name\n",
    "        # Or .../images/split_name if images is a top-level component in the path from YAML.\n",
    "        temp_path_parts = full_image_dir.split(os.sep)\n",
    "        found_images_segment = False\n",
    "        for i in range(len(temp_path_parts) -1, -1, -1): # Iterate backwards\n",
    "            if temp_path_parts[i].lower() == 'images':\n",
    "                temp_path_parts[i] = 'labels'\n",
    "                full_label_dir = os.sep.join(temp_path_parts)\n",
    "                found_images_segment = True\n",
    "                break\n",
    "        if not found_images_segment: # If 'images' is not in the path, try making 'labels' a sibling of the image folder's parent\n",
    "             # e.g. if full_image_dir = /data/my_set/train_imgs, labels could be /data/my_set/train_labels\n",
    "             # This is a heuristic. A common structure is .../dataset_root/[images|labels]/split\n",
    "             # If full_image_dir is '.../dataset_X/train', labels might be '.../dataset_X/labels_train' or '.../dataset_X/labels/train'\n",
    "             # Simplest assumption if 'images' not in path: labels are in a parallel folder to image folder's direct parent.\n",
    "             # e.g., if images are in dataset_root/train_images, labels are in dataset_root/train_labels\n",
    "             # A more robust way for common ultralytics structure:\n",
    "             # if dataset_root_abs/images/train, then dataset_root_abs/labels/train\n",
    "             # if dataset_root_abs/train (and this is an image folder), then dataset_root_abs needs a labels folder\n",
    "             if config.get('path'): # If 'path' (dataset_root) was defined\n",
    "                 split_basename = os.path.basename(full_image_dir) # e.g. 'train'\n",
    "                 # Check if full_image_dir is like dataset_root_abs/images/split\n",
    "                 if os.path.basename(os.path.dirname(full_image_dir)).lower() == 'images':\n",
    "                     # This case should have been caught by the loop above.\n",
    "                     pass\n",
    "                 else: # Assume full_image_dir is like dataset_root_abs/split (e.g. .../coco128/train)\n",
    "                       # Then labels are dataset_root_abs/labels/split\n",
    "                    full_label_dir = os.path.join(dataset_root_abs, 'labels', split_basename)\n",
    "\n",
    "        if not full_label_dir: # Default fallback if above logic didn't set it\n",
    "            raise ValueError(\"Could not determine standard label directory structure.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not reliably infer label directory from image directory '{full_image_dir}'. Error: {e}\")\n",
    "        print(\"Will proceed without attempting to load bounding boxes unless a 'labels' directory is found by convention.\")\n",
    "        # Try a simple convention as a last resort if full_label_dir is still empty\n",
    "        if not full_label_dir:\n",
    "             parent = os.path.dirname(full_image_dir)\n",
    "             base = os.path.basename(full_image_dir)\n",
    "             full_label_dir = os.path.join(parent, base.replace(\"images\", \"labels\")) # crude replace\n",
    "             if not os.path.isdir(full_label_dir): # if that fails, try structure like dataset_root/labels/split_name\n",
    "                full_label_dir = os.path.join(dataset_root_abs, 'labels', os.path.basename(full_image_dir))\n",
    "\n",
    "\n",
    "    print(f\"Attempting to use label directory: {full_label_dir}\")\n",
    "\n",
    "    if not os.path.isdir(full_image_dir):\n",
    "        print(f\"Error: Final constructed image directory '{full_image_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    image_files = [f for f in os.listdir(full_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not image_files:\n",
    "        print(f\"No images found in '{full_image_dir}'.\")\n",
    "        return\n",
    "    print(f\"Found {len(image_files)} images in '{full_image_dir}'.\")\n",
    "\n",
    "    labels_available = os.path.isdir(full_label_dir)\n",
    "    if not labels_available:\n",
    "         print(f\"Warning: Label directory '{full_label_dir}' does not exist. Bounding boxes will not be shown.\")\n",
    "\n",
    "    selected_images = random.sample(image_files, min(num_images_to_show, len(image_files)))\n",
    "\n",
    "    for image_name in selected_images:\n",
    "        image_path = os.path.join(full_image_dir, image_name)\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        label_path = os.path.join(full_label_dir, label_name)\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        img_height, img_width = img.shape[:2]\n",
    "        img_display = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB) # For matplotlib\n",
    "\n",
    "        annotations_found_for_this_image = False\n",
    "        if labels_available and os.path.exists(label_path):\n",
    "            try:\n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line_num, line in enumerate(f):\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) < 5:\n",
    "                            print(f\"Warning: Malformed line #{line_num+1} in {label_path}: '{line.strip()}' (expected 5+ values)\")\n",
    "                            continue\n",
    "                        try:\n",
    "                            class_id = int(float(parts[0])) # class_id can sometimes be float in files like 0.0\n",
    "                            bbox_norm = list(map(float, parts[1:5])) # x_center, y_center, width, height\n",
    "                        except ValueError:\n",
    "                            print(f\"Warning: Could not parse numerical values in line #{line_num+1} in {label_path}: '{line.strip()}'\")\n",
    "                            continue\n",
    "                        \n",
    "                        x_min, y_min, x_max, y_max = denormalize_bbox(bbox_norm, img_width, img_height)\n",
    "                        \n",
    "                        current_class_name = f\"ID:{class_id}\" # Default\n",
    "                        if isinstance(class_names, dict): # Handles 'names: {0: name1, 1: name2}'\n",
    "                            current_class_name = class_names.get(class_id, f\"ID:{class_id}\")\n",
    "                        elif isinstance(class_names, list): # Handles 'names: [name1, name2]'\n",
    "                            if 0 <= class_id < len(class_names):\n",
    "                                current_class_name = class_names[class_id]\n",
    "                            else:\n",
    "                                print(f\"Warning: Class ID {class_id} out of bounds for class_names list (len {len(class_names)}) in {label_path}.\")\n",
    "                        \n",
    "                        cv2.rectangle(img_display, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2) # Green box\n",
    "                        cv2.putText(img_display, current_class_name, (x_min, y_min - 10 if y_min > 20 else y_min + 20), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                        annotations_found_for_this_image = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or processing label file {label_path}: {e}\")\n",
    "        \n",
    "        if labels_available and not annotations_found_for_this_image and not os.path.exists(label_path):\n",
    "            print(f\"Label file not found: {label_path}\")\n",
    "        elif not labels_available and not annotations_found_for_this_image:\n",
    "            # This is expected if label directory was not found earlier.\n",
    "            pass\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(img_display)\n",
    "        plt.title(f\"Image: {image_name} (from {dataset_split} set)\\nLabels from: {label_path if annotations_found_for_this_image else 'N/A'}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# --- How to use: ---\n",
    "# 1. Save the code above as a Python file (e.g., view_dataset.py).\n",
    "# 2. Make sure you have the necessary libraries: pip install pyyaml opencv-python matplotlib\n",
    "# 3. Call the function with the path to your data.yaml file.\n",
    "\n",
    "# Example:\n",
    "# If your data.yaml is in the same directory as the script:\n",
    "# visualize_dataset_sample('data.yaml', num_images_to_show=5, dataset_split='train')\n",
    "\n",
    "# Or provide the full path:\n",
    "# visualize_dataset_sample('/path/to/your/dataset/data.yaml', num_images_to_show=5, dataset_split='val')\n",
    "\n",
    "# To use with your provided training script context:\n",
    "# Assuming your data.yaml is correctly configured and accessible.\n",
    "# Add this to a new script or at the end of your existing one (outside main guard):\n",
    "if __name__ == '__main__':\n",
    "    # --- IMPORTANT ---\n",
    "    # Replace 'path/to/your/data.yaml' with the actual path to your data.yaml file.\n",
    "    # Your training script uses data=\"data.yaml\", so if this script is in the same \n",
    "    # directory as data.yaml and your dataset, you can just use 'data.yaml'.\n",
    "    data_yaml_file = \"/blue/hulcr/gmarais/PhD/phase_1_data/3_classification_phase_2/ultralytics/cv_iteration_1/data.yaml\" # Or the correct path to your data.yaml\n",
    "\n",
    "    print(\"\\n--- Important Note on Dataset Type ---\")\n",
    "    print(\"You mentioned your dataset is for 'image classification'.\")\n",
    "    print(\"Standard Ultralytics image classification datasets are structured by class folders\")\n",
    "    print(\"(e.g., dataset/train/class1/image.jpg) and do NOT use .txt files for bounding box annotations.\")\n",
    "    print(\"Bounding boxes are typically used for 'object detection' datasets.\")\n",
    "    print(\"This script is designed to visualize bounding boxes from .txt label files common in object detection.\")\n",
    "    print(\"If your dataset is purely for classification without .txt label files, it will display images without bounding boxes.\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    visualize_dataset_sample(data_yaml_file, num_images_to_show=10, dataset_split='train')\n",
    "    # You can also try the 'val' split:\n",
    "    # visualize_dataset_sample(data_yaml_file, num_images_to_show=3, dataset_split='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
